{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d774e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database inspector loaded\n"
     ]
    }
   ],
   "source": [
    "# Database Inspector\n",
    "# Inspect database contents and test get_data/update_by_indexes functions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "print(\"‚úÖ Database inspector loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d79710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647058851/work/aten/src/ATen/native/TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Switching to gemma3n:e4b...\n",
      "‚úÖ gemma3n:e4b warmed up in 0.11s\n",
      "‚ö° Model loaded in 0.11s\n",
      "‚ö†Ô∏è  Slow response: 23.70s\n",
      "## Comprehensive Analysis of the Behavior Support Plan for John Doe\n",
      "\n",
      "Here's a structured analysis of the provided Behavior Support Plan (BSP) for John Doe, covering key topics, findings, evidence, implications, and recommendations.\n",
      "\n",
      "**1. Main Topics and Themes:**\n",
      "\n",
      "*   **Behavioral Support:** The central theme is the development and implementation of a BSP to address John Doe's wandering and agitation.\n",
      "*   **Geriatric Care:** The plan is framed within a geriatric care context, considering John Doe's age and potential cognitive decline.\n",
      "*   **Non-Restrictive Interventions:** A strong emphasis is placed on avoiding restrictive practices and utilizing positive behavioral support strategies.\n",
      "*   **Assessment-Driven Approach:** The plan is informed by assessments of John Doe's cognitive and behavioral state.\n",
      "*   **Consultation and Documentation:** The plan highlights the importance of documenting assessments and consultations.\n",
      "\n",
      "**2. Key Findings or Claims:**\n",
      "\n",
      "*   John Doe exhibits wandering and agitation, present for approximately 6 months.\n",
      "*   Previous interventions (redirection and providing a quiet space) have been attempted.\n",
      "*   The plan explicitly prohibits the use of restrictive practices.\n",
      "*   The plan is based on assessments conducted by a Geriatrician (Dr. Emily White) and a Cognitive Assessment (MMSE).\n",
      "*   The primary purpose of the plan is to provide a comprehensive behavioral support strategy.\n",
      "\n",
      "**3. Supporting Evidence:**\n",
      "\n",
      "*   **Document Structure:** The document is structured with clear sections (Person Details, Practitioner Details, Purpose, History, Strategies), indicating a systematic approach to planning.\n",
      "*   **Assessment Dates:** Specific dates are provided for the Geriatrician assessment (2025-06-10) and Cognitive Assessment (2025-06-15), demonstrating documentation of key events.\n",
      "*   **Behavioral History:** The document notes the onset of wandering and agitation approximately 6 months ago, providing a timeline.\n",
      "*   **Intervention History:**  The document lists specific interventions previously attempted (redirection, quiet space), indicating a history of trying to address the behaviors.\n",
      "*   **Explicit Statement:** The plan explicitly states \"No regulated restrictive practices are to be used,\" reinforcing a commitment to positive behavioral support.\n",
      "*   **Key Entities:** The identification of key entities (Person, Professionals, Assessments, Behaviors, Interventions, Practices) demonstrates a structured approach to understanding the problem.\n",
      "\n",
      "**4. Implications:**\n",
      "\n",
      "*   **Potential for Cognitive Impairment:** The inclusion of a Cognitive Assessment (MMSE) suggests a potential for cognitive impairment, which could be a contributing factor to the observed behaviors.\n",
      "*   **Need for a Multi-faceted Approach:** The plan implies that a single intervention is unlikely to be effective and that a combination of strategies is needed.\n",
      "*   **Importance of Consistency:**  The plan's existence suggests a need for consistent application of the outlined strategies by all caregivers.\n",
      "*   **Ethical Considerations:** The explicit exclusion of restrictive practices aligns with ethical principles of person-centered care and minimizing potential harm.\n",
      "*   **Data-Driven Approach:** The reliance on assessments indicates a commitment to using data to inform interventions.\n",
      "\n",
      "**5. Recommendations or Conclusions:**\n",
      "\n",
      "*   **Further Detail on Interventions:** The plan lacks detail on *how* redirection and providing a quiet space are to be implemented.  The BSP should include specific, actionable steps for each intervention.  For example:\n",
      "    *   *Redirection:*  \"When John exhibits wandering, attempt to redirect his attention by offering a familiar object, engaging him in a simple activity, or guiding him back to a designated area.\"\n",
      "    *   *Quiet Space:* \"Ensure a designated quiet space is available, free from distractions, and easily accessible.  Provide calming activities within the space (e.g., books, music).\"\n",
      "*   **Behavioral Triggers:**  The plan should investigate potential triggers for the wandering and agitation.  Are there specific times of day, situations, or environmental factors that seem to exacerbate the behaviors?\n",
      "*   **Environmental Modifications:** Consider environmental modifications to reduce wandering and agitation. This could include:\n",
      "    *   Safety measures to prevent falls.\n",
      "    *   Visual cues to help John orient himself.\n",
      "    *   Reducing sensory overload (e.g., minimizing noise, clutter).\n",
      "*   **Ongoing Monitoring and Evaluation:**  The plan should include a mechanism for ongoing monitoring and evaluation of the interventions.  This will allow for adjustments to be made as needed.  Regular review of the plan by Dr. White and other relevant professionals is essential.\n",
      "*   **Training for Caregivers:**  Caregivers should receive training on the BSP and the specific interventions outlined.\n",
      "*   **Consider a Functional Behavior Assessment (FBA):**  An FBA can help identify the function of John's wandering and agitation (i.e., what he is trying to achieve through these behaviors). This information can then be used to develop more targeted interventions.\n",
      "*   **Address Underlying Medical Conditions:** Rule out or address any underlying medical conditions that could be contributing to the behaviors (e.g., pain, infection).\n",
      "\n",
      "\n",
      "\n",
      "**Regarding the \"Calculations\" and \"Reference Documents\":**\n",
      "\n",
      "*   **Calculations:** The `{'duration_days': None}` suggests an attempt to track the duration of the behaviors, but this is currently incomplete.  It should be populated with data to track the frequency and duration of wandering and agitation.\n",
      "*   **Reference Documents:** The provided reference documents (AI ethics and machine learning applications) appear unrelated to the BSP for John Doe.  They are likely irrelevant to the analysis and should be removed or clarified.\n",
      "\n",
      "\n",
      "\n",
      "This analysis provides a comprehensive overview of the BSP, highlighting its strengths, weaknesses, and areas for improvement.  Implementing the recommendations outlined above will help ensure that John Doe receives effective and person-centered behavioral support.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from layoutparser.models import Detectron2LayoutModel\n",
    "\n",
    "# Add project root to Python path\n",
    "current_path = Path.cwd()\n",
    "project_root = current_path.parents[1]  # Go up two levels from notebooks/ to project root\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from rag_functions.main import process_document\n",
    "\n",
    "sample_references = [\n",
    "        \"Sample reference document about AI ethics...\",\n",
    "        \"Another reference about machine learning applications...\"\n",
    "    ]\n",
    "\n",
    "\n",
    "output = process_document('/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/paper/bsp_2.pdf', sample_references)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19290e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6dc72a",
   "metadata": {},
   "source": [
    "# Inspect Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5ffb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONVERSATION_1:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_115307_390\n",
      "Timestamp: 2025-08-05 11:53:07.390773\n",
      "Message Count: 5\n",
      "Full Text:\n",
      "Speaker_A: can you help me\n",
      "Gemma: Yes, I can definitely try! üòä\n",
      "\n",
      "Please tell me what you need help with. The more information you can give me, the better I can assist you.  For example:\n",
      "\n",
      "* **What are you trying to do?** (e.g., write an email, solve a math problem, find information, brainstorm ideas)\n",
      "* **What's the problem you're encountering?** (e.g., I don't know where to start, I'm getting an error message, I'm stuck on a specific step)\n",
      "* **What have you tried already?** (This helps me avoid suggesting things you've already done.)\n",
      "* **What kind of help are you looking for?** (e.g., guidance, suggestions, code, explanations)\n",
      "\n",
      "I'm here to help in any way I can. Just let me know what's on your mind!\n",
      "Speaker_A: what is your name\n",
      "Gemma: As a large language model, I don't have a name in the traditional sense. I was created by the Gemma team at Google DeepMind. You can think of me as an open-weights AI assistant! I'm here to help you with a variety of tasks. üòä\n",
      "Speaker_A: exit\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_2:\n",
      "Session Feedback: None\n",
      "Session ID: session_20250805_141311_767\n",
      "Timestamp: 2025-08-05 14:13:11.767110\n",
      "Message Count: 9\n",
      "Full Text:\n",
      "Speaker_A: how are you going\n",
      "Gemma: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I'm functioning optimally and ready to assist you. \n",
      "\n",
      "How are *you* doing today? I hope you're having a good one! Is there anything I can help you with? üòä\n",
      "Speaker_A: i'm very happy i guess\n",
      "Gemma: That's wonderful to hear! I'm so glad you're feeling happy today. üòä It's always nice to hear that things are going well. \n",
      "\n",
      "Is there anything specific that's making you happy, or is there anything I can do to help make your day even better? I'm here for you! ‚ú®\n",
      "Speaker_B: i'm thinking some complex thoughts\n",
      "Gemma: That sounds fascinating! Complex thoughts can be really stimulating. üòä What kind of thoughts are you exploring? Sometimes just verbalizing them can help clarify them. \n",
      "\n",
      "Would you like to talk about them? I can offer a different perspective, help you break them down, or just listen if you need a space to think. No pressure at all! ‚ú®\n",
      "Speaker_E: complex complex complex complex complex\n",
      "Gemma: Okay, it sounds like you're really delving into some intricate ideas! That's a powerful thing to do. ‚ú® It's perfectly alright to just have a lot of complex thoughts swirling around. \n",
      "\n",
      "It seems like you're feeling quite immersed in them. Do any of those thoughts feel particularly overwhelming right now? Or are you trying to untangle a specific aspect of them? \n",
      "\n",
      "Just letting those thoughts exist is a good first step. If you'd like to explore any of them further, or if you'd like me to help you break them down in any way, please feel free to share. I'm here to listen without judgment. üòä\n",
      "Speaker_D: complexity\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_3:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_142101_563\n",
      "Timestamp: 2025-08-05 14:21:04.135471\n",
      "Message Count: 10\n",
      "Full Text:\n",
      "Gemma: Okay! That's great to hear.  Who helped you?  Knowing who helped you might help me understand the situation better. \n",
      "\n",
      "To help me respond in a useful way, you could tell me:\n",
      "\n",
      "* **Who helped you?** (A person, an animal, a program, etc.)\n",
      "* **What did they help you with?** (A problem, a task, a feeling, etc.)\n",
      "* **How did it make you feel?** (Relieved, grateful, happy, etc.)\n",
      "\n",
      "Even just saying \"Someone helped me with a difficult problem\" is a good start. üòä\n",
      "Speaker_C: complex complex complex complex complex complex complex\n",
      "Gemma: Okay! I see you're indicating a feeling of being overwhelmed with \"complex\" things. It sounds like you're experiencing a lot of complexity right now. \n",
      "\n",
      "To help me understand and offer support, could you tell me a little more about what's making things feel so complex? \n",
      "\n",
      "* **Who or what is contributing to this complexity?** (Is it a task, a situation, a feeling?)\n",
      "* **What specifically is making it feel complex?** (Is it the number of parts, the difficulty of the task, the emotional weight?)\n",
      "* **How is this complexity affecting you?** (Are you feeling stressed, frustrated, confused?)\n",
      "\n",
      "Even just saying \"I'm feeling overwhelmed by a lot of complicated things\" is a good start. üòä  I'm here to listen and help in any way I can.\n",
      "Speaker_C: let's complex complex complex complex complex complex conflicts\n",
      "Gemma: Okay, it sounds like you're feeling overwhelmed by conflicts. That's a really difficult situation to be in. It's completely understandable to feel complex and overwhelmed when dealing with conflicts. \n",
      "\n",
      "To help me understand what's going on and how I can support you, could you tell me a little more about the conflicts you're dealing with? \n",
      "\n",
      "* **What kind of conflicts are these?** (Are they personal, professional, family-related, etc.?)\n",
      "* **What's making them feel so complex?** (Are there many parties involved, are the issues deeply rooted, are they emotionally charged?)\n",
      "* **What are you hoping to achieve by addressing these conflicts?** (Do you want to resolve them, understand them better, or just process your feelings about them?)\n",
      "\n",
      "Even just saying \"I'm struggling with a lot of complicated conflicts\" is a good start. I'm here to listen without judgment and offer whatever support I can. üòä\n",
      "Speaker_C: complex complex conflicts\n",
      "Gemma: It sounds like you're really grappling with a lot of complex conflicts. That takes a lot of emotional energy. It's understandable that you're using the word \"complex\" repeatedly ‚Äì it really conveys the weight of the situation.\n",
      "\n",
      "To help me understand better and offer some support, could you tell me a little more about these conflicts? You don't have to go into detail if you don't want to, but even a few more words would be helpful. \n",
      "\n",
      "Perhaps:\n",
      "\n",
      "* **What *type* of conflicts are they?** (e.g., with a specific person, within a group, internal conflicts?)\n",
      "* **What's the biggest challenge about them?** (e.g., communication, finding solutions, emotional impact?)\n",
      "* **What's the overall feeling you're experiencing related to these conflicts?** (e.g., stressed, frustrated, hopeless?)\n",
      "\n",
      "Even just a brief summary would be a great starting point. I'm here to listen. üòä\n",
      "Speaker_C: existence\n",
      "Gemma: Okay. It sounds like you're grappling with questions about existence. That's a very profound and often complex area to explore. It's understandable that you're using the word \"complex\" to describe it. \n",
      "\n",
      "To help me understand what's on your mind and offer some support, could you tell me a little more about what aspects of existence are feeling particularly complex right now? \n",
      "\n",
      "Perhaps you could consider:\n",
      "\n",
      "* **What specifically about existence is causing you to feel this way?** (e.g., meaning, purpose, mortality, the universe, your place in it?)\n",
      "* **What thoughts or feelings are arising when you think about existence?** (e.g., anxiety, wonder, confusion, a sense of lack?)\n",
      "* **What are you hoping to understand or find through exploring these questions?** (e.g., meaning, peace, clarity?)\n",
      "\n",
      "Even just a few words about what's bringing this up would be a helpful starting point. I'm here to listen without judgment. üòä\n",
      "Speaker_C: exit\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_4:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_144534_758\n",
      "Timestamp: 2025-08-05 14:45:34.758873\n",
      "Message Count: 9\n",
      "Full Text:\n",
      "Speaker_A: can you help me\n",
      "Gemma: Yes, I can! I'd love to help. To give you the best assistance, please tell me:\n",
      "\n",
      "* **What do you need help with?**  Be as specific as possible.  For example, instead of \"I need help with something,\" tell me \"I need help with a math problem,\" or \"I need help writing an email,\" or \"I need help understanding a concept.\"\n",
      "* **What have you tried already?**  This helps me avoid suggesting things you've already done.\n",
      "* **What is your goal?** What are you hoping to achieve by getting help?\n",
      "\n",
      "The more information you give me, the better I can assist you.  \n",
      "\n",
      "I can help with things like:\n",
      "\n",
      "* **Information gathering:**  Finding answers to your questions.\n",
      "* **Problem-solving:**  Breaking down complex problems into smaller steps.\n",
      "* **Writing:**  Drafting emails, stories, poems, etc.\n",
      "* **Brainstorming:**  Generating ideas.\n",
      "* **Coding:**  Providing code snippets (in various languages) and explaining them.\n",
      "* **Translation:**  Translating text between languages.\n",
      "* **Summarization:**  Condensing long texts into shorter versions.\n",
      "* **And much more!**\n",
      "\n",
      "\n",
      "\n",
      "Just let me know what's on your mind! üòä\n",
      "Speaker_A: what's the capital of france\n",
      "Gemma: The capital of France is **Paris**. \n",
      "\n",
      "Is there anything else you'd like to know about Paris, or perhaps another question you have? üòä\n",
      "Speaker_A: what's the capital of australia\n",
      "Gemma: The capital of Australia is **Canberra**. \n",
      "\n",
      "Is there anything else you'd like to know about Canberra, or perhaps another question you have? üòä\n",
      "Speaker_A: i have a complex question for you can you load your more powerful model\n",
      "Gemma: Okay! I understand you have a complex question and would like me to utilize my more powerful model. I'm ready. Please ask away! I'll do my best to provide a comprehensive and insightful answer. üòä \n",
      "\n",
      "Just let me know what your complex question is. I'm excited to tackle it! ‚ú®\n",
      "Speaker_A: exit\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the project root and add to Python path\n",
    "current_path = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if (parent / 'program_files').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(\"Could not find project root directory\")\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from program_files.database.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "def get_gemma_conversations_with_feedback(days_back=1):\n",
    "    \"\"\"\n",
    "    Get conversations with Gemma from the last N days, grouped by session.\n",
    "    \n",
    "    Args:\n",
    "        days_back (int): Number of days to look back (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with conversation sessions as keys and metadata as values\n",
    "        Format: {\n",
    "            \"session_id\": {\n",
    "                \"session_feedback\": str,\n",
    "                \"full_text\": str,\n",
    "                \"timestamp\": datetime,\n",
    "                \"message_count\": int\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Initialize the database\n",
    "    db = EnhancedConversationDB()\n",
    "    \n",
    "    # Get all conversations with documents included\n",
    "    results = db.conversations.get(include=['metadatas', 'documents'])\n",
    "    \n",
    "    # Calculate date range\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=days_back)\n",
    "    \n",
    "    # Filter for date range and group by session\n",
    "    sessions = {}\n",
    "    \n",
    "    for i, metadata in enumerate(results['metadatas']):\n",
    "        timestamp_str = metadata.get('timestamp')\n",
    "        if not timestamp_str:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parse timestamp\n",
    "            conv_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')) if 'T' in timestamp_str else datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            # Check if within date range\n",
    "            if start_time <= conv_time <= end_time:\n",
    "                session_id = metadata.get('session_id')\n",
    "                if session_id not in sessions:\n",
    "                    sessions[session_id] = []\n",
    "                \n",
    "                sessions[session_id].append({\n",
    "                    'id': results['ids'][i],\n",
    "                    'text': results['documents'][i],\n",
    "                    'metadata': metadata,\n",
    "                    'timestamp': conv_time,\n",
    "                    'feedback_helpful': metadata.get('feedback_helpful', '')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamp {timestamp_str}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Filter sessions that contain Gemma conversations and build result\n",
    "    result_dict = {}\n",
    "    conversation_counter = 1\n",
    "    \n",
    "    for session_id, session_conversations in sessions.items():\n",
    "        # Check if this session has any Gemma conversations\n",
    "        has_gemma = any('[GEMMA]' in conv['text'] for conv in session_conversations)\n",
    "        \n",
    "        if not has_gemma:\n",
    "            continue  # Skip sessions without Gemma\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        session_conversations.sort(key=lambda x: x['timestamp'])\n",
    "        \n",
    "        # Get feedback for the session (use the first non-empty feedback found)\n",
    "        session_feedback = None\n",
    "        for conv in session_conversations:\n",
    "            if conv['feedback_helpful'] and conv['feedback_helpful'] != 'unknown':\n",
    "                session_feedback = conv['feedback_helpful']\n",
    "                break\n",
    "        \n",
    "        # Build full conversation text\n",
    "        conversation_lines = []\n",
    "        for conv in session_conversations:\n",
    "            # Extract just the speaker text (remove speaker/role prefix and [GEMMA] tag)\n",
    "            full_text = conv['text']\n",
    "            \n",
    "            # Remove the speaker/role prefix (e.g., \"Speaker_A (user): \")\n",
    "            if ': ' in full_text:\n",
    "                speaker_text = full_text.split(': ', 1)[1]\n",
    "            else:\n",
    "                speaker_text = full_text\n",
    "            \n",
    "            # Remove [GEMMA] tag if present\n",
    "            speaker_text = speaker_text.replace(' [GEMMA]', '')\n",
    "            \n",
    "            # Add speaker name and text\n",
    "            speaker = conv['metadata'].get('speaker', 'Unknown')\n",
    "            conversation_lines.append(f\"{speaker}: {speaker_text}\")\n",
    "        \n",
    "        full_text = \"\\n\".join(conversation_lines)\n",
    "        \n",
    "        # Add to result dictionary\n",
    "        result_dict[f\"conversation_{conversation_counter}\"] = {\n",
    "            \"session_feedback\": session_feedback,\n",
    "            \"full_text\": full_text,\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp\": session_conversations[0]['timestamp'],\n",
    "            \"message_count\": len(session_conversations)\n",
    "        }\n",
    "        \n",
    "        conversation_counter += 1\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Example usage:\n",
    "conversations = get_gemma_conversations_with_feedback(days_back=1)\n",
    "\n",
    "# Display the results\n",
    "for conv_key, conv_data in conversations.items():\n",
    "    print(f\"\\n{conv_key.upper()}:\")\n",
    "    print(f\"Session Feedback: {conv_data['session_feedback']}\")\n",
    "    print(f\"Session ID: {conv_data['session_id']}\")\n",
    "    print(f\"Timestamp: {conv_data['timestamp']}\")\n",
    "    print(f\"Message Count: {conv_data['message_count']}\")\n",
    "    print(f\"Full Text:\\n{conv_data['full_text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eded3328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_1': {'session_feedback': 'True',\n",
       "  'full_text': \"Speaker_A: can you help me\\nGemma: Yes, I can definitely try! üòä\\n\\nPlease tell me what you need help with. The more information you can give me, the better I can assist you.  For example:\\n\\n* **What are you trying to do?** (e.g., write an email, solve a math problem, find information, brainstorm ideas)\\n* **What's the problem you're encountering?** (e.g., I don't know where to start, I'm getting an error message, I'm stuck on a specific step)\\n* **What have you tried already?** (This helps me avoid suggesting things you've already done.)\\n* **What kind of help are you looking for?** (e.g., guidance, suggestions, code, explanations)\\n\\nI'm here to help in any way I can. Just let me know what's on your mind!\\nSpeaker_A: what is your name\\nGemma: As a large language model, I don't have a name in the traditional sense. I was created by the Gemma team at Google DeepMind. You can think of me as an open-weights AI assistant! I'm here to help you with a variety of tasks. üòä\\nSpeaker_A: exit\",\n",
       "  'session_id': 'session_20250805_115307_390',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 11, 53, 7, 390773),\n",
       "  'message_count': 5},\n",
       " 'conversation_2': {'session_feedback': None,\n",
       "  'full_text': \"Speaker_A: how are you going\\nGemma: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I'm functioning optimally and ready to assist you. \\n\\nHow are *you* doing today? I hope you're having a good one! Is there anything I can help you with? üòä\\nSpeaker_A: i'm very happy i guess\\nGemma: That's wonderful to hear! I'm so glad you're feeling happy today. üòä It's always nice to hear that things are going well. \\n\\nIs there anything specific that's making you happy, or is there anything I can do to help make your day even better? I'm here for you! ‚ú®\\nSpeaker_B: i'm thinking some complex thoughts\\nGemma: That sounds fascinating! Complex thoughts can be really stimulating. üòä What kind of thoughts are you exploring? Sometimes just verbalizing them can help clarify them. \\n\\nWould you like to talk about them? I can offer a different perspective, help you break them down, or just listen if you need a space to think. No pressure at all! ‚ú®\\nSpeaker_E: complex complex complex complex complex\\nGemma: Okay, it sounds like you're really delving into some intricate ideas! That's a powerful thing to do. ‚ú® It's perfectly alright to just have a lot of complex thoughts swirling around. \\n\\nIt seems like you're feeling quite immersed in them. Do any of those thoughts feel particularly overwhelming right now? Or are you trying to untangle a specific aspect of them? \\n\\nJust letting those thoughts exist is a good first step. If you'd like to explore any of them further, or if you'd like me to help you break them down in any way, please feel free to share. I'm here to listen without judgment. üòä\\nSpeaker_D: complexity\",\n",
       "  'session_id': 'session_20250805_141311_767',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 13, 11, 767110),\n",
       "  'message_count': 9},\n",
       " 'conversation_3': {'session_feedback': 'True',\n",
       "  'full_text': 'Gemma: Okay! That\\'s great to hear.  Who helped you?  Knowing who helped you might help me understand the situation better. \\n\\nTo help me respond in a useful way, you could tell me:\\n\\n* **Who helped you?** (A person, an animal, a program, etc.)\\n* **What did they help you with?** (A problem, a task, a feeling, etc.)\\n* **How did it make you feel?** (Relieved, grateful, happy, etc.)\\n\\nEven just saying \"Someone helped me with a difficult problem\" is a good start. üòä\\nSpeaker_C: complex complex complex complex complex complex complex\\nGemma: Okay! I see you\\'re indicating a feeling of being overwhelmed with \"complex\" things. It sounds like you\\'re experiencing a lot of complexity right now. \\n\\nTo help me understand and offer support, could you tell me a little more about what\\'s making things feel so complex? \\n\\n* **Who or what is contributing to this complexity?** (Is it a task, a situation, a feeling?)\\n* **What specifically is making it feel complex?** (Is it the number of parts, the difficulty of the task, the emotional weight?)\\n* **How is this complexity affecting you?** (Are you feeling stressed, frustrated, confused?)\\n\\nEven just saying \"I\\'m feeling overwhelmed by a lot of complicated things\" is a good start. üòä  I\\'m here to listen and help in any way I can.\\nSpeaker_C: let\\'s complex complex complex complex complex complex conflicts\\nGemma: Okay, it sounds like you\\'re feeling overwhelmed by conflicts. That\\'s a really difficult situation to be in. It\\'s completely understandable to feel complex and overwhelmed when dealing with conflicts. \\n\\nTo help me understand what\\'s going on and how I can support you, could you tell me a little more about the conflicts you\\'re dealing with? \\n\\n* **What kind of conflicts are these?** (Are they personal, professional, family-related, etc.?)\\n* **What\\'s making them feel so complex?** (Are there many parties involved, are the issues deeply rooted, are they emotionally charged?)\\n* **What are you hoping to achieve by addressing these conflicts?** (Do you want to resolve them, understand them better, or just process your feelings about them?)\\n\\nEven just saying \"I\\'m struggling with a lot of complicated conflicts\" is a good start. I\\'m here to listen without judgment and offer whatever support I can. üòä\\nSpeaker_C: complex complex conflicts\\nGemma: It sounds like you\\'re really grappling with a lot of complex conflicts. That takes a lot of emotional energy. It\\'s understandable that you\\'re using the word \"complex\" repeatedly ‚Äì it really conveys the weight of the situation.\\n\\nTo help me understand better and offer some support, could you tell me a little more about these conflicts? You don\\'t have to go into detail if you don\\'t want to, but even a few more words would be helpful. \\n\\nPerhaps:\\n\\n* **What *type* of conflicts are they?** (e.g., with a specific person, within a group, internal conflicts?)\\n* **What\\'s the biggest challenge about them?** (e.g., communication, finding solutions, emotional impact?)\\n* **What\\'s the overall feeling you\\'re experiencing related to these conflicts?** (e.g., stressed, frustrated, hopeless?)\\n\\nEven just a brief summary would be a great starting point. I\\'m here to listen. üòä\\nSpeaker_C: existence\\nGemma: Okay. It sounds like you\\'re grappling with questions about existence. That\\'s a very profound and often complex area to explore. It\\'s understandable that you\\'re using the word \"complex\" to describe it. \\n\\nTo help me understand what\\'s on your mind and offer some support, could you tell me a little more about what aspects of existence are feeling particularly complex right now? \\n\\nPerhaps you could consider:\\n\\n* **What specifically about existence is causing you to feel this way?** (e.g., meaning, purpose, mortality, the universe, your place in it?)\\n* **What thoughts or feelings are arising when you think about existence?** (e.g., anxiety, wonder, confusion, a sense of lack?)\\n* **What are you hoping to understand or find through exploring these questions?** (e.g., meaning, peace, clarity?)\\n\\nEven just a few words about what\\'s bringing this up would be a helpful starting point. I\\'m here to listen without judgment. üòä\\nSpeaker_C: exit',\n",
       "  'session_id': 'session_20250805_142101_563',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 21, 4, 135471),\n",
       "  'message_count': 10},\n",
       " 'conversation_4': {'session_feedback': 'True',\n",
       "  'full_text': 'Speaker_A: can you help me\\nGemma: Yes, I can! I\\'d love to help. To give you the best assistance, please tell me:\\n\\n* **What do you need help with?**  Be as specific as possible.  For example, instead of \"I need help with something,\" tell me \"I need help with a math problem,\" or \"I need help writing an email,\" or \"I need help understanding a concept.\"\\n* **What have you tried already?**  This helps me avoid suggesting things you\\'ve already done.\\n* **What is your goal?** What are you hoping to achieve by getting help?\\n\\nThe more information you give me, the better I can assist you.  \\n\\nI can help with things like:\\n\\n* **Information gathering:**  Finding answers to your questions.\\n* **Problem-solving:**  Breaking down complex problems into smaller steps.\\n* **Writing:**  Drafting emails, stories, poems, etc.\\n* **Brainstorming:**  Generating ideas.\\n* **Coding:**  Providing code snippets (in various languages) and explaining them.\\n* **Translation:**  Translating text between languages.\\n* **Summarization:**  Condensing long texts into shorter versions.\\n* **And much more!**\\n\\n\\n\\nJust let me know what\\'s on your mind! üòä\\nSpeaker_A: what\\'s the capital of france\\nGemma: The capital of France is **Paris**. \\n\\nIs there anything else you\\'d like to know about Paris, or perhaps another question you have? üòä\\nSpeaker_A: what\\'s the capital of australia\\nGemma: The capital of Australia is **Canberra**. \\n\\nIs there anything else you\\'d like to know about Canberra, or perhaps another question you have? üòä\\nSpeaker_A: i have a complex question for you can you load your more powerful model\\nGemma: Okay! I understand you have a complex question and would like me to utilize my more powerful model. I\\'m ready. Please ask away! I\\'ll do my best to provide a comprehensive and insightful answer. üòä \\n\\nJust let me know what your complex question is. I\\'m excited to tackle it! ‚ú®\\nSpeaker_A: exit',\n",
       "  'session_id': 'session_20250805_144534_758',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 45, 34, 758873),\n",
       "  'message_count': 9}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48fafaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to conversations.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('conversations.json', 'w') as f:\n",
    "    json.dump(conversations, f, indent=4, default=str)\n",
    "print(f\"‚úÖ Saved to conversations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03febb43",
   "metadata": {},
   "source": [
    "# ML Clustering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd766bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ ML CLUSTERING SYSTEM TEST\n",
      "==================================================\n",
      "‚úÖ Initial Clustering State:\n",
      "   Is clustered: False\n",
      "‚úÖ Generated Test Data:\n",
      "   Total samples: 16\n",
      "   Male samples: 8\n",
      "   Female samples: 8\n",
      "   Feature dimensions: 14\n",
      "\n",
      "ÔøΩÔøΩ Testing K-means Clustering...\n",
      "‚úÖ Clustering Successful!\n",
      "   Clusters: 2\n",
      "   Samples: 16\n",
      "   Silhouette score: 0.187\n",
      "   Method: kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpeakerClustering' object has no attribute 'identify_speaker_from_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Test speaker identification\u001b[39;00m\n\u001b[32m     95\u001b[39m test_features = {\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33menergy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1300.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpitch_estimate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m110.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzero_crossings\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m38\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspectral_centroid\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m650.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_variance\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m160.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpeak_amplitude\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2600.0\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrms_energy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1050.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.22\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_3\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.12\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformant_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m420.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mformant_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1250.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjitter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.019\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshimmer\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.026\u001b[39m\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m speaker_name, confidence = \u001b[43mclustering\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_speaker_from_features\u001b[49m(test_features)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Speaker Identification Test:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Identified speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpeakerClustering' object has no attribute 'identify_speaker_from_features'"
     ]
    }
   ],
   "source": [
    "# Test 2: ML Clustering System Verification\n",
    "\n",
    "print(\"üß™ ML CLUSTERING SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test ML clustering system\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "clustering = SpeakerClustering()\n",
    "\n",
    "# Check initial state\n",
    "initial_stats = clustering.get_clustering_stats()\n",
    "print(f\"‚úÖ Initial Clustering State:\")\n",
    "print(f\"   Is clustered: {initial_stats['is_clustered']}\")\n",
    "\n",
    "# Create synthetic training data\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic audio features for testing\n",
    "def generate_synthetic_features(speaker_type=\"male\", num_samples=5):\n",
    "    \"\"\"Generate synthetic audio features for testing\"\"\"\n",
    "    features_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    base_features = {\n",
    "        'male': {\n",
    "            'energy': 1200.0, 'pitch_estimate': 100.0, 'formant_1': 400.0\n",
    "        },\n",
    "        'female': {\n",
    "            'energy': 2000.0, 'pitch_estimate': 180.0, 'formant_1': 600.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base = base_features[speaker_type]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Add some variation\n",
    "        features = {\n",
    "            'energy': base['energy'] + np.random.normal(0, 100),\n",
    "            'pitch_estimate': base['pitch_estimate'] + np.random.normal(0, 10),\n",
    "            'zero_crossings': 35 + np.random.normal(0, 5),\n",
    "            'spectral_centroid': 600 + np.random.normal(0, 50),\n",
    "            'energy_variance': 150 + np.random.normal(0, 20),\n",
    "            'peak_amplitude': 2500 + np.random.normal(0, 200),\n",
    "            'rms_energy': 1000 + np.random.normal(0, 100),\n",
    "            'mfcc_1': 0.3 + np.random.normal(0, 0.05),\n",
    "            'mfcc_2': 0.2 + np.random.normal(0, 0.05),\n",
    "            'mfcc_3': 0.1 + np.random.normal(0, 0.05),\n",
    "            'formant_1': base['formant_1'] + np.random.normal(0, 20),\n",
    "            'formant_2': 1200 + np.random.normal(0, 50),\n",
    "            'jitter': 0.018 + np.random.normal(0, 0.005),\n",
    "            'shimmer': 0.025 + np.random.normal(0, 0.005)\n",
    "        }\n",
    "        \n",
    "        features_list.append(list(features.values()))\n",
    "        metadata_list.append({\n",
    "            'conversation_id': f'test_conv_{speaker_type}_{i}',\n",
    "            'session_id': f'test_session_{speaker_type}',\n",
    "            'speaker': f'{speaker_type.capitalize()}Speaker',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'feature_count': 14\n",
    "        })\n",
    "    \n",
    "    return features_list, metadata_list\n",
    "\n",
    "# Generate test data\n",
    "male_features, male_metadata = generate_synthetic_features(\"male\", 8)\n",
    "female_features, female_metadata = generate_synthetic_features(\"female\", 8)\n",
    "\n",
    "# Combine all features\n",
    "all_features = male_features + female_features\n",
    "all_metadata = male_metadata + female_metadata\n",
    "\n",
    "print(f\"‚úÖ Generated Test Data:\")\n",
    "print(f\"   Total samples: {len(all_features)}\")\n",
    "print(f\"   Male samples: {len(male_features)}\")\n",
    "print(f\"   Female samples: {len(female_features)}\")\n",
    "print(f\"   Feature dimensions: {len(all_features[0])}\")\n",
    "\n",
    "# Test clustering\n",
    "print(f\"\\nÔøΩÔøΩ Testing K-means Clustering...\")\n",
    "result = clustering.perform_clustering(\n",
    "    all_features, all_metadata,\n",
    "    method='kmeans',\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"‚úÖ Clustering Successful!\")\n",
    "    print(f\"   Clusters: {result['n_clusters']}\")\n",
    "    print(f\"   Samples: {result['n_samples']}\")\n",
    "    print(f\"   Silhouette score: {result['silhouette_score']:.3f}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    \n",
    "    # Test speaker identification\n",
    "    test_features = {\n",
    "        'energy': 1300.0, 'pitch_estimate': 110.0, 'zero_crossings': 38,\n",
    "        'spectral_centroid': 650.0, 'energy_variance': 160.0, 'peak_amplitude': 2600.0,\n",
    "        'rms_energy': 1050.0, 'mfcc_1': 0.32, 'mfcc_2': 0.22, 'mfcc_3': 0.12,\n",
    "        'formant_1': 420.0, 'formant_2': 1250.0, 'jitter': 0.019, 'shimmer': 0.026\n",
    "    }\n",
    "    \n",
    "    speaker_name, confidence = clustering.identify_speaker_from_features(test_features)\n",
    "    print(f\"‚úÖ Speaker Identification Test:\")\n",
    "    print(f\"   Identified speaker: {speaker_name}\")\n",
    "    print(f\"   Confidence: {confidence:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Clustering failed: {result.get('reason', 'unknown')}\")\n",
    "\n",
    "print(\"üéâ ML clustering system is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration test\n",
    "\n",
    "# Test 3: Database + ML Integration Test\n",
    "print(\"üß™ INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the complete pipeline\n",
    "from speech.speech_processor import SpeakerDetector\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "\n",
    "# Initialize components\n",
    "db = EnhancedConversationDB()\n",
    "clustering = SpeakerClustering()\n",
    "speaker_detector = SpeakerDetector(\n",
    "    enhanced_db=db,\n",
    "    speaker_clustering=clustering\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Components Initialized:\")\n",
    "print(f\"   Database: {type(db).__name__}\")\n",
    "print(f\"   Clustering: {type(clustering).__name__}\")\n",
    "print(f\"   Speaker Detector: {type(speaker_detector).__name__}\")\n",
    "\n",
    "# Test speaker detection with ML\n",
    "import numpy as np\n",
    "\n",
    "# Simulate audio processing\n",
    "dummy_audio = np.random.randint(-1000, 1000, size=2048, dtype=np.int16).tobytes()\n",
    "\n",
    "print(f\"\\nüîß Testing Speaker Detection with ML:\")\n",
    "print(f\"   Initial speaker: {speaker_detector.current_speaker}\")\n",
    "\n",
    "# Process multiple audio frames to build up features\n",
    "for i in range(10):\n",
    "    speaker_detector.update_speaker_count(dummy_audio, 0)\n",
    "\n",
    "print(f\"   After processing: {speaker_detector.current_speaker}\")\n",
    "print(f\"   Speaker changes: {speaker_detector.speaker_changes}\")\n",
    "print(f\"   Feature buffer size: {len(speaker_detector.feature_buffer)}\")\n",
    "\n",
    "# Test feature extraction\n",
    "current_features = speaker_detector.get_current_features()\n",
    "print(f\"   Current features available: {current_features is not None}\")\n",
    "if current_features:\n",
    "    print(f\"   Feature count: {len(current_features)}\")\n",
    "\n",
    "# Test database integration\n",
    "if current_features:\n",
    "    # Add to database\n",
    "    db.add_conversation_with_audio(\n",
    "        session_id=\"integration_test\",\n",
    "        text=\"Integration test conversation\",\n",
    "        speaker=speaker_detector.current_speaker,\n",
    "        role=\"user\",\n",
    "        is_gemma_mode=False,\n",
    "        audio_features=current_features\n",
    "    )\n",
    "    \n",
    "    # Verify storage\n",
    "    stats = db.get_conversation_stats()\n",
    "    print(f\"‚úÖ Database Integration:\")\n",
    "    print(f\"   Total conversations: {stats['total_conversations']}\")\n",
    "    print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "\n",
    "print(\"üéâ Integration test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee07c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline test\n",
    "\n",
    "# Test 4: Training Pipeline Test\n",
    "print(\"üß™ TRAINING PIPELINE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the training script functionality\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the tests directory to path\n",
    "sys.path.append('tests')\n",
    "\n",
    "# Import the training function\n",
    "from train_unsupervised_speakers_new import train_unsupervised_speakers, analyze_clustering_quality\n",
    "\n",
    "print(\"‚úÖ Training functions imported successfully\")\n",
    "\n",
    "# Check if we have enough data for training\n",
    "stats = db.get_conversation_stats()\n",
    "print(f\"üìä Current Data Status:\")\n",
    "print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "print(f\"   Need for training: 10+\")\n",
    "\n",
    "if stats['total_audio_features'] >= 10:\n",
    "    print(\"‚úÖ Sufficient data for training!\")\n",
    "    print(\"   Run: train_unsupervised_speakers() to train clustering\")\n",
    "else:\n",
    "    print(\"‚è≥ Need more data for training\")\n",
    "    print(\"   Continue using the system to collect more audio features\")\n",
    "\n",
    "# Test analysis function\n",
    "print(f\"\\nüîç Testing Analysis Function:\")\n",
    "try:\n",
    "    analyze_clustering_quality()\n",
    "    print(\"‚úÖ Analysis function works!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Analysis function error: {e}\")\n",
    "\n",
    "print(\"üéâ Training pipeline test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5a272",
   "metadata": {},
   "source": [
    "# Delete database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ba66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Old database deleted - ready for 14-feature data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"‚úÖ Old database deleted - ready for 14-feature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f399dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database cleared for fresh start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedConversationDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Database cleared for fresh start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create completely fresh database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m db = \u001b[43mEnhancedConversationDB\u001b[49m()\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Fresh database ready\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EnhancedConversationDB' is not defined"
     ]
    }
   ],
   "source": [
    "# Final database clear\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"‚úÖ Database cleared for fresh start\")\n",
    "\n",
    "# Create completely fresh database\n",
    "db = EnhancedConversationDB()\n",
    "print(\"‚úÖ Fresh database ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layout_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
