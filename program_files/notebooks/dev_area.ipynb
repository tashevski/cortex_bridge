{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d774e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database inspector loaded\n"
     ]
    }
   ],
   "source": [
    "# Database Inspector\n",
    "# Inspect database contents and test get_data/update_by_indexes functions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "print(\"✅ Database inspector loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647058851/work/aten/src/ATen/native/TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Analysis of Behavior Support Plan for John Doe\n",
      "\n",
      "Here's a structured analysis of the provided behavior support plan summary for John Doe, addressing the key medical concerns, likely problems, and implications.\n",
      "\n",
      "**1. Main Topics and Themes:**\n",
      "\n",
      "*   **Behavioral Challenges:** The central theme revolves around John Doe's behavioral difficulties, specifically wandering and agitation.\n",
      "*   **Geriatric Care:** The document clearly falls within the domain of geriatric care, addressing behavioral issues common in older adults.\n",
      "*   **Non-Restrictive Interventions:** A strong emphasis is placed on avoiding restrictive practices, indicating a commitment to person-centered care.\n",
      "*   **Assessment and Monitoring:** The plan incorporates ongoing assessment (cognitive and behavioral) to inform interventions.\n",
      "*   **Multidisciplinary Approach:** The inclusion of a Geriatrician and Cognitive Assessment suggests a collaborative approach to care.\n",
      "\n",
      "**2. Key Findings or Claims:**\n",
      "\n",
      "*   **Wandering and Agitation:** John Doe has been exhibiting wandering and agitation for approximately six months. This is the primary behavioral concern.\n",
      "*   **Cognitive Impairment:** A Mini-Mental State Examination (MMSE) was conducted on 2025-06-15, suggesting a potential cognitive impairment.  (The results of the MMSE are not provided, but its inclusion is significant).\n",
      "*   **Previous Interventions Ineffective/Insufficient:**  Prior attempts to manage the behavior (redirection, quiet space) have been insufficient to fully address the issue.\n",
      "*   **Commitment to Non-Restrictive Care:** The plan explicitly states that no regulated restrictive practices are to be used.\n",
      "\n",
      "**3. Supporting Evidence:**\n",
      "\n",
      "*   **Geriatrician Assessment (2025-06-10):**  This indicates a formal medical evaluation has been conducted.\n",
      "*   **Cognitive Assessment (MMSE) (2025-06-15):**  Provides evidence of an evaluation for cognitive function.  The MMSE is a standard tool for assessing cognitive status.\n",
      "*   **History of Behavioral Issues:** The documented onset of wandering and agitation approximately six months ago provides a timeline for the problem.\n",
      "*   **Previous Intervention Records:**  The mention of redirection and quiet space indicates attempts have been made to manage the behavior.\n",
      "*   **Explicit Statement Regarding Restrictive Practices:** This is a clear statement of intent and a key element of the plan.\n",
      "\n",
      "**4. Implications:**\n",
      "\n",
      "*   **Potential for Increased Risk:** Wandering poses a significant risk of falls, disorientation, and potential harm to John Doe. Agitation can lead to self-injury or aggression.\n",
      "*   **Possible Underlying Medical Condition:** The wandering and agitation, coupled with the cognitive assessment, suggest a possible underlying medical condition contributing to the behavior (e.g., dementia, delirium, other neurological issues).\n",
      "*   **Need for Tailored Interventions:**  Generic approaches are unlikely to be effective. Interventions must be tailored to John Doe's specific needs and the underlying cause of the behavior.\n",
      "*   **Importance of a Supportive Environment:**  The plan implies a need for a calm, predictable, and safe environment to minimize agitation and wandering.\n",
      "*   **Caregiver Burden:**  Behavioral challenges can place a significant burden on caregivers.\n",
      "\n",
      "**5. Recommendations or Conclusions:**\n",
      "\n",
      "*   **Further Investigation of Underlying Cause:**  A thorough medical evaluation is needed to determine the underlying cause of the wandering and agitation. This should include a review of John Doe's medical history, medication review, and potentially further neurological or psychiatric assessment.\n",
      "*   **Behavioral Analysis:** A more detailed behavioral analysis is required to understand the triggers for the wandering and agitation. This could involve direct observation and data collection.\n",
      "*   **Development of a Comprehensive Behavioral Intervention Plan:**  Based on the underlying cause and behavioral analysis, a detailed plan should be developed. This plan should include:\n",
      "    *   **Environmental Modifications:**  Creating a safe and predictable environment (e.g., removing hazards, providing familiar objects).\n",
      "    *   **Communication Strategies:**  Using clear, simple communication to reduce confusion and anxiety.\n",
      "    *   **Redirection Techniques:**  Developing specific redirection techniques that are tailored to John Doe's preferences and abilities.\n",
      "    *   **Activity-Based Interventions:**  Engaging John Doe in meaningful activities to reduce boredom and agitation.\n",
      "    *   **Medication Review:**  Consulting with a physician to determine if medication can be used to manage the underlying cause of the behavior. (While restrictive practices are prohibited, medication may be appropriate in some cases).\n",
      "*   **Regular Monitoring and Evaluation:**  The plan should be regularly monitored and evaluated to assess its effectiveness and make adjustments as needed.\n",
      "*   **Caregiver Support:**  Provide support and resources to caregivers to help them manage John Doe's behavior and reduce their burden.\n",
      "*   **Consideration of Dementia-Specific Resources:** If dementia is suspected, explore dementia-specific resources and support programs.\n",
      "\n",
      "\n",
      "\n",
      "**Disclaimer:** This analysis is based solely on the provided summary. A complete understanding of John Doe's situation requires access to the full document and further clinical information. This analysis is not a substitute for professional medical advice.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from layoutparser.models import Detectron2LayoutModel\n",
    "\n",
    "# Add project root to Python path\n",
    "current_path = Path.cwd()\n",
    "project_root = current_path.parents[1]  # Go up two levels from notebooks/ to project root\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from rag_functions.main import process_document\n",
    "\n",
    "template_entity_extraction=\"\"\"<start_of_turn>system\n",
    "You are an expert at identifying and extracting entities from text.\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>user\n",
    "Document: {context}\n",
    "\n",
    "Task: {prompt}\n",
    "\n",
    "Extract and categorize all relevant entities:\n",
    "- People/Organizations\n",
    "- Dates/Times\n",
    "- Locations\n",
    "- Key Concepts/Terms\n",
    "- Numerical Data\n",
    "- Relationships\n",
    "\n",
    "Format as structured lists.\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\"\"\"\n",
    "\n",
    "\n",
    "sample_references = [\n",
    "        \"medical and care advice for family\",\n",
    "        \"medical and care advice for medical staff\"\n",
    "    ]\n",
    "\n",
    "# sample_references = \"provide support for a family member of the patient who is a carer\"\n",
    "# sample_reference = \"\"\"\n",
    "# Extract key medical and care advice for family, please advise what is the most appropriate response for different likely problems the patient is \n",
    "# likely to face given the information provided\n",
    "\n",
    "# Return your answers in the following format, with each answer wrapped in curly brackets:\n",
    "#         {{[likely problem]: [brief advise based on the information provided]}}\n",
    "#         {{[likely problem]: [brief advise based on the information provided]}}\n",
    "#         {{[likely problem]: [brief advise based on the information provided]}}\n",
    "#         {{[likely problem]: [brief advise based on the information provided]}}\n",
    "#         {{[likely problem]: [brief advise based on the information provided]}}\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# \"identify series of likely problems the patient is likely to face given the information provided\"\n",
    "\n",
    "# \"respond to each likely problem with a brief advise based on the information provided\"\n",
    "\n",
    "\n",
    "\n",
    "sample_references = \"identify the key medical concerns and likely problems the patient is likely to face given the information provided\"\n",
    "\n",
    "\n",
    "#output = process_document('/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/paper/bsp_2.pdf', sample_references)\n",
    "output = process_document('/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/paper/bsp_2.pdf', prompt=sample_references)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19290e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased risk of falls and injuries due to wandering.\n",
      "Emotional distress and frustration stemming from agitation and disorientation.\n",
      "Communication difficulties leading to unmet needs and increased agitation.\n",
      "Potential for medical complications related to agitation (e.g., increased heart rate, anxiety).\n",
      "Caregiver burnout and emotional strain due to managing behavioral challenges.\n",
      "Difficulty maintaining personal safety while attempting to redirect or assist John Doe.\n",
      "Social isolation due to behavioral issues impacting participation in activities.\n",
      "Increased anxiety and fear for John Doe's well-being from wandering and potential for getting lost.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(output)+1):\n",
    "    print(output[f'question_{i}']['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff29670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/alexander/miniforge3/envs/layout_parser/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/alexander/miniforge3/envs/layout_parser/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'select_optimal_templates' from 'rag_functions.templates.prompt_templates' (/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/rag_functions/templates/prompt_templates.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrag_functions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_document\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrag_functions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemplates\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_templates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m select_optimal_templates, extract_cue_cards\n\u001b[1;32m     34\u001b[0m output \u001b[38;5;241m=\u001b[39m process_document(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/paper/bsp_2.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'select_optimal_templates' from 'rag_functions.templates.prompt_templates' (/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/rag_functions/templates/prompt_templates.py)"
     ]
    }
   ],
   "source": [
    "detailed_template = \"\"\"<start_of_turn>system\n",
    "  You are a knowledgeable assistant. Answer questions thoroughly based on \n",
    "  the provided context.\n",
    "  <end_of_turn>\n",
    "\n",
    "  <start_of_turn>user\n",
    "  Reference Material: {context}\n",
    "\n",
    "  Question: {prompt}\n",
    "\n",
    "  Please provide:\n",
    "  1. A direct answer to the question\n",
    "  2. Supporting evidence from the context\n",
    "  3. Any relevant additional insights\n",
    "  4. Confidence level in your answer\n",
    "  <end_of_turn>\n",
    "\n",
    "  <start_of_turn>model\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from layoutparser.models import Detectron2LayoutModel\n",
    "\n",
    "# Add project root to Python path\n",
    "current_path = Path.cwd()\n",
    "project_root = current_path.parents[1]  # Go up two levels from notebooks/ to project root\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from rag_functions.core.main import process_document\n",
    "from rag_functions.templates.prompt_templates import select_optimal_templates, extract_cue_cards\n",
    "\n",
    "output = process_document('/Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/paper/bsp_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d307f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis': \"## Comprehensive Behavior Support Plan for John Doe: Analysis and Treatment Plan\\n\\n**Date:** October 26, 2023\\n\\n**Prepared for:** John Doe\\n\\n**Prepared by:** AI Healthcare Provider\\n\\n**Disclaimer:** This treatment plan is based on the provided clinical data and is intended for informational purposes only. It does not constitute medical advice and should be reviewed and individualized by a qualified healthcare professional in collaboration with John Doe and his family/caregivers.\\n\\n---\\n\\n### **I. Comprehensive Analysis of Document Analysis**\\n\\n**Key Findings:**\\n\\n* **Problem:** John Doe has experienced wandering and agitation for approximately 6 months.\\n* **Assessment:**  A geriatric assessment (2025-06-10) and cognitive assessment (MMSE, 2025-06-15) have been conducted. The results of these assessments are not provided in the document, representing a significant gap in information.\\n* **Prior Interventions:**  Initial interventions focused on redirection and providing a quiet space have been attempted, with limited success.\\n* **Restraint Avoidance:**  The plan explicitly states no regulated restrictive practices are to be used, emphasizing a person-centered approach.\\n* **Key Entities:** The document identifies key stakeholders (person, professionals), issues (behaviors), and categories (interventions, practices).\\n\\n**Analysis of Entities:**\\n\\n* **Person (John Doe):**  The central focus.  The behaviors (wandering, agitation) are likely symptoms of an underlying medical or cognitive condition.  Understanding John Doe's history, preferences, and values is crucial for person-centered care.\\n* **Professionals (Dr. Emily White):**  The geriatrician provides medical oversight and expertise.  Collaboration with Dr. White is essential for medication management and overall care.\\n* **Assessments (Geriatric & Cognitive):**  These are critical for diagnosis and guiding treatment.  The absence of specific results from these assessments is a major limitation.\\n* **Behaviors (Wandering, Agitation):**  These are the target of the intervention.  Understanding the triggers and underlying causes of these behaviors is essential.\\n* **Interventions (Redirection, Quiet Space):**  These are initial, non-pharmacological approaches.  Their ineffectiveness suggests a need for more comprehensive and tailored interventions.\\n* **Practices (Restrictive Practices):**  Explicitly excluded, reflecting a commitment to ethical and person-centered care.\\n\\n**Interpretation of Data:**\\n\\nThe data suggests John Doe is experiencing behavioral symptoms likely related to a geriatric condition, potentially involving cognitive impairment. The lack of specific assessment results hinders a complete understanding of the underlying cause. The initial interventions have been insufficient, indicating a need for a more detailed and multi-faceted treatment plan.\\n\\n**Gaps in Information:**\\n\\n* **Results of Geriatric and Cognitive Assessments:**  Crucial for diagnosis and guiding treatment.\\n* **Specific Triggers for Wandering and Agitation:**  Identifying triggers is essential for proactive intervention.\\n* **Underlying Medical Conditions:**  Identifying any co-existing medical conditions is important.\\n* **John Doe's Preferences and Values:**  Understanding his wishes and priorities is vital for person-centered care.\\n\\n\\n\\n### **II. Comprehensive Treatment Plan**\\n\\n**A. Problem List:**\\n\\n* **Primary Diagnosis (Likely):**\\n    * **Dementia (Specify type if known):**  F00-F02 (ICD-10).  *Note: This is a likely diagnosis given the age and reported behaviors.  Confirmation requires cognitive assessment results.*\\n    * **Vascular Dementia:** F00.2 (ICD-10) - If history of vascular risk factors.\\n    * **Alzheimer's Disease:** F00.0 (ICD-10) - Most common type of dementia.\\n* **Secondary Conditions (To be determined based on assessment):**\\n    * **Depression:** F32 (ICD-10) - Common comorbidity with dementia.\\n    * **Anxiety:** F41 (ICD-10) - Can exacerbate behavioral issues.\\n    * **Sleep Disorders:** G47 (ICD-10) - Can contribute to agitation.\\n    * **Pain:** R50-R53 (ICD-10) -  Chronic pain can worsen behavioral symptoms.\\n* **Risk Factors:**\\n    * Advanced age\\n    * Potential vascular risk factors (hypertension, diabetes, hyperlipidemia) - *To be determined.*\\n    * History of cognitive decline\\n* **Psychosocial Considerations:**\\n    * Potential for social isolation and loneliness.\\n    * Impact on family caregivers.\\n    * Loss of independence and cognitive decline can lead to frustration and behavioral changes.\\n\\n**B. Treatment Goals:**\\n\\n**Short-Term Goals (1-3 months):**\\n\\n* Reduce frequency and severity of wandering by 50%.\\n* Decrease agitation episodes by 30%.\\n* Establish a predictable daily routine.\\n* Identify and address potential triggers for wandering and agitation.\\n* Improve communication and emotional regulation skills.\\n\\n**Long-Term Goals (6-12 months):**\\n\\n* Maintain safety and well-being while promoting independence.\\n* Minimize behavioral disturbances through consistent and person-centered interventions.\\n* Improve quality of life for John Doe and his family.\\n* Reduce reliance on pharmacological interventions where possible.\\n* Enhance caregiver support and education.\\n\\n**Functional Outcomes:**\\n\\n* John Doe will be able to participate in meaningful activities with minimal distress.\\n* John Doe will maintain adequate nutrition and hydration.\\n* John Doe will maintain personal hygiene.\\n* John Doe will experience reduced anxiety and agitation.\\n\\n**Quality of Life Measures:**\\n\\n* Improved mood and emotional well-being.\\n* Increased social engagement (if appropriate and desired).\\n* Enhanced sense of purpose and meaning.\\n* Reduced feelings of frustration and helplessness.\\n\\n**C. Therapeutic Interventions:**\\n\\n**1. Pharmacological Treatments:**\\n\\n* **Approach:**  Medication should be considered *only* after non-pharmacological interventions have been implemented and after a thorough assessment by Dr. White.  The goal is to address underlying medical conditions contributing to behavioral symptoms, not to suppress behavior.\\n* **Potential Medications (Examples - to be determined by Dr. White):**\\n    * **Antidepressants (SSRIs):** For co-existing depression/anxiety.  *Monitoring: Side effects, efficacy.*\\n    * **Antipsychotics (Low Dose):**  *Only* if other causes have been ruled out and agitation is severe and posing a safety risk.  *Monitoring: Extrapyramidal symptoms, metabolic changes, cardiac function.*\\n    * **Anxiolytics (e.g., Buspirone):** For anxiety. *Monitoring: Sedation, dizziness.*\\n    * **Sleep Aids (e.g., Melatonin):** For sleep disturbances. *Monitoring: Sedation, daytime drowsiness.*\\n* **Dosing:**  Doses will be determined by Dr. White based on individual needs and medical history.\\n* **Drug Interactions:**  A thorough drug interaction check will be performed before initiating any new medication.\\n* **Monitoring Parameters:**  Regular monitoring of vital signs, laboratory tests (e.g., liver function, kidney function), and side effects.\\n\\n**2. Non-Pharmacological Interventions:**\\n\\n* **Lifestyle Modifications:**\\n    * **Regular Physical Activity:**  Encourage daily walks or exercises to reduce agitation and improve mood.\\n    * **Consistent Sleep Schedule:**  Establish a regular sleep-wake cycle.\\n    * **Healthy Diet:**  Ensure adequate nutrition and hydration.\\n    * **Sensory Stimulation:**  Provide engaging activities that stimulate the senses (e.g., music, art, aromatherapy).\\n* **Physical Therapy:**  Address any physical limitations that may contribute to wandering or agitation.  Improve mobility and balance.\\n* **Counseling/Education:**\\n    * **Caregiver Education:**  Provide caregivers with education on dementia, behavioral interventions, and coping strategies.\\n    * **Cognitive Behavioral Therapy (CBT) adapted for Dementia:**  Help John Doe identify and manage triggers for agitation.\\n    * **Validation Therapy:**  Acknowledge and validate John Doe's feelings, even if his perceptions are inaccurate.\\n    * **Reality Orientation:**  Provide reminders of time, place, and person (use cautiously, as it can be distressing).\\n* **Environmental Modifications:**\\n    * **Safe Environment:**  Ensure a safe and secure environment with minimal hazards.\\n    * **Familiarity:**  Maintain a familiar and comfortable environment.\\n    * **Reduce Clutter:**  Minimize clutter to reduce confusion and disorientation.\\n    * **Visual Cues:**  Use visual cues (e.g., pictures, labels) to aid orientation.\\n* **Routine and Structure:** Establish a predictable daily routine to reduce anxiety and confusion.\\n\\n**3. Procedural Interventions:**\\n\\n* **Surgical Considerations:**  *Not typically indicated for behavioral issues.*  Address any underlying medical conditions that may be contributing to behavioral symptoms.\\n* **Minimally Invasive Options:**  *Not typically indicated for behavioral issues.*  Consider if there are underlying medical conditions that can be addressed with minimally invasive procedures.\\n\\n**D. Monitoring Plan:**\\n\\n* **Clinical Parameters to Track:**\\n    * Frequency and severity of wandering and agitation.\\n    * Sleep patterns.\\n    * Appetite and weight.\\n    * Mood and emotional state.\\n    * Physical health (vital signs, lab results).\\n* **Laboratory Monitoring Schedule:**\\n    * Annual comprehensive physical exam with blood work (including thyroid function, vitamin B12, and other relevant markers).\\n    * As needed, based on clinical findings.\\n* **Imaging Follow-up:**\\n    * MRI or CT scan of the brain (if not previously performed or if clinically indicated).\\n* **Functional Assessments:**\\n    * Regular assessment of functional abilities (e.g., Activities of Daily Living - ADLs) to monitor changes over time.\\n    * Use standardized assessment tools (e.g., Functional Activities Questionnaire - FAQ).\\n\\n**E. Contingency Planning:**\\n\\n* **Treatment Failure Scenarios:**\\n    * Re-evaluate diagnosis and treatment plan with Dr. White.\\n    * Consider alternative pharmacological interventions.\\n    * Intensify non-pharmacological interventions.\\n    * Consult with a behavioral specialist.\\n* **Adverse Event Management:**\\n    * Have a plan in place to manage any adverse events related to medication or interventions.\\n    * Monitor for and address any side effects promptly.\\n* **Alternative Therapies:**\\n    * Consider complementary therapies (e.g., music therapy, art therapy, pet therapy) in consultation with Dr. White.\\n* **Emergency Protocols:**\\n    * Develop a plan for managing emergency situations (e.g., falls, medical emergencies).\\n    * Ensure access to emergency medical services.\\n\\n---\\n\\n**F. Patient Preferences:**\\n\\n* **Crucially, this plan must be individualized to John Doe's preferences and values.**  This requires ongoing communication with John Doe (if possible) and his family/caregivers.\\n* **Examples of considerations:**\\n    *  Respecting his autonomy and dignity.\\n    *  Maintaining his privacy.\\n    *  Involving him in decision-making to the extent possible.\\n    *  Providing opportunities for social engagement.\\n    *  Addressing his emotional needs.\\n\\n\\n\\n**Next Steps:**\\n\\n1. **Obtain and review results of Geriatric and Cognitive Assessments.**\\n2. **Conduct a comprehensive assessment of John Doe's medical history, psychosocial factors, and current medications.**\\n3. **Develop a detailed care plan in collaboration with Dr. White, John Doe, and his family/caregivers.**\\n4. **Implement the treatment plan and monitor progress regularly.**\\n5. **Adjust the plan as needed based on John Doe's response and changing needs.**\\n\\n\\n\\nThis comprehensive treatment plan provides a framework for addressing John Doe's behavioral symptoms.  It is essential to remember that this is a dynamic plan that should be individualized and adjusted based on his needs and preferences.  Ongoing communication and collaboration with all stakeholders are crucial for success.\",\n",
       " 'template_info': {'template_name': 'treatment_plan',\n",
       "  'confidence': np.float32(0.3373962),\n",
       "  'all_recommendations': [('treatment_plan', np.float32(0.3373962)),\n",
       "   ('care_coordination', np.float32(0.3247481)),\n",
       "   ('progress_note', np.float32(0.31743664))]},\n",
       " 'cue_cards': {'main': {'cue_cards': [CueCard(title='[Wandering/Agitation]', context='[Wandering/Agitation]', key_points=[\"Validate John Doe's feelings, prioritize person-centered care, and conduct a comprehensive assessment of medical history, psychosocial factors, and medications, adjusting the plan based on his response.\"], priority='medium', category='medical'),\n",
       "    CueCard(title='[Possible Dementia (likely)', context='[Possible Dementia (likely)', key_points=['Obtain and review results of geriatric and cognitive assessments to confirm diagnosis and guide treatment plan.]'], priority='medium', category='medical'),\n",
       "    CueCard(title='[Wandering/Agitation]', context='[Wandering/Agitation]', key_points=['Implement comprehensive, person-centered interventions including trigger identification, routine establishment, lifestyle modifications (exercise, sleep schedule, sensory stimulation), and consider pharmacological options (after non-pharmacological failure & physician assessment) for underlying conditions like anxiety, sleep disorders, or pain.'], priority='medium', category='medical'),\n",
       "    CueCard(title='[Person-Centered Care Plan]', context='[Person-Centered Care Plan]', key_points=['Prioritize restraint avoidance, understand triggers, modify environment for safety and familiarity, and support independence, social engagement, and emotional well-being while respecting autonomy and involving stakeholders.'], priority='medium', category='medical'),\n",
       "    CueCard(title='[Insufficient Initial Intervention]', context='[Insufficient Initial Intervention]', key_points=['Collaborate with Dr. White for a detailed, multi-faceted treatment plan, considering underlying medical conditions and vascular risk factors, with regular monitoring of vital signs, labs, and medication effects.'], priority='medium', category='medical')]}},\n",
       " 'document_type_scores': {'intake': np.float32(0.29758787),\n",
       "  'clinical': np.float32(0.26129133),\n",
       "  'report': np.float32(0.18613705),\n",
       "  'diagnostic': np.float32(0.19358084),\n",
       "  'treatment': np.float32(0.3480265)}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6dc72a",
   "metadata": {},
   "source": [
    "# Inspect Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5ffb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONVERSATION_1:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_115307_390\n",
      "Timestamp: 2025-08-05 11:53:07.390773\n",
      "Message Count: 5\n",
      "Full Text:\n",
      "Speaker_A: can you help me\n",
      "Gemma: Yes, I can definitely try! 😊\n",
      "\n",
      "Please tell me what you need help with. The more information you can give me, the better I can assist you.  For example:\n",
      "\n",
      "* **What are you trying to do?** (e.g., write an email, solve a math problem, find information, brainstorm ideas)\n",
      "* **What's the problem you're encountering?** (e.g., I don't know where to start, I'm getting an error message, I'm stuck on a specific step)\n",
      "* **What have you tried already?** (This helps me avoid suggesting things you've already done.)\n",
      "* **What kind of help are you looking for?** (e.g., guidance, suggestions, code, explanations)\n",
      "\n",
      "I'm here to help in any way I can. Just let me know what's on your mind!\n",
      "Speaker_A: what is your name\n",
      "Gemma: As a large language model, I don't have a name in the traditional sense. I was created by the Gemma team at Google DeepMind. You can think of me as an open-weights AI assistant! I'm here to help you with a variety of tasks. 😊\n",
      "Speaker_A: exit\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_2:\n",
      "Session Feedback: None\n",
      "Session ID: session_20250805_141311_767\n",
      "Timestamp: 2025-08-05 14:13:11.767110\n",
      "Message Count: 9\n",
      "Full Text:\n",
      "Speaker_A: how are you going\n",
      "Gemma: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I'm functioning optimally and ready to assist you. \n",
      "\n",
      "How are *you* doing today? I hope you're having a good one! Is there anything I can help you with? 😊\n",
      "Speaker_A: i'm very happy i guess\n",
      "Gemma: That's wonderful to hear! I'm so glad you're feeling happy today. 😊 It's always nice to hear that things are going well. \n",
      "\n",
      "Is there anything specific that's making you happy, or is there anything I can do to help make your day even better? I'm here for you! ✨\n",
      "Speaker_B: i'm thinking some complex thoughts\n",
      "Gemma: That sounds fascinating! Complex thoughts can be really stimulating. 😊 What kind of thoughts are you exploring? Sometimes just verbalizing them can help clarify them. \n",
      "\n",
      "Would you like to talk about them? I can offer a different perspective, help you break them down, or just listen if you need a space to think. No pressure at all! ✨\n",
      "Speaker_E: complex complex complex complex complex\n",
      "Gemma: Okay, it sounds like you're really delving into some intricate ideas! That's a powerful thing to do. ✨ It's perfectly alright to just have a lot of complex thoughts swirling around. \n",
      "\n",
      "It seems like you're feeling quite immersed in them. Do any of those thoughts feel particularly overwhelming right now? Or are you trying to untangle a specific aspect of them? \n",
      "\n",
      "Just letting those thoughts exist is a good first step. If you'd like to explore any of them further, or if you'd like me to help you break them down in any way, please feel free to share. I'm here to listen without judgment. 😊\n",
      "Speaker_D: complexity\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_3:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_142101_563\n",
      "Timestamp: 2025-08-05 14:21:04.135471\n",
      "Message Count: 10\n",
      "Full Text:\n",
      "Gemma: Okay! That's great to hear.  Who helped you?  Knowing who helped you might help me understand the situation better. \n",
      "\n",
      "To help me respond in a useful way, you could tell me:\n",
      "\n",
      "* **Who helped you?** (A person, an animal, a program, etc.)\n",
      "* **What did they help you with?** (A problem, a task, a feeling, etc.)\n",
      "* **How did it make you feel?** (Relieved, grateful, happy, etc.)\n",
      "\n",
      "Even just saying \"Someone helped me with a difficult problem\" is a good start. 😊\n",
      "Speaker_C: complex complex complex complex complex complex complex\n",
      "Gemma: Okay! I see you're indicating a feeling of being overwhelmed with \"complex\" things. It sounds like you're experiencing a lot of complexity right now. \n",
      "\n",
      "To help me understand and offer support, could you tell me a little more about what's making things feel so complex? \n",
      "\n",
      "* **Who or what is contributing to this complexity?** (Is it a task, a situation, a feeling?)\n",
      "* **What specifically is making it feel complex?** (Is it the number of parts, the difficulty of the task, the emotional weight?)\n",
      "* **How is this complexity affecting you?** (Are you feeling stressed, frustrated, confused?)\n",
      "\n",
      "Even just saying \"I'm feeling overwhelmed by a lot of complicated things\" is a good start. 😊  I'm here to listen and help in any way I can.\n",
      "Speaker_C: let's complex complex complex complex complex complex conflicts\n",
      "Gemma: Okay, it sounds like you're feeling overwhelmed by conflicts. That's a really difficult situation to be in. It's completely understandable to feel complex and overwhelmed when dealing with conflicts. \n",
      "\n",
      "To help me understand what's going on and how I can support you, could you tell me a little more about the conflicts you're dealing with? \n",
      "\n",
      "* **What kind of conflicts are these?** (Are they personal, professional, family-related, etc.?)\n",
      "* **What's making them feel so complex?** (Are there many parties involved, are the issues deeply rooted, are they emotionally charged?)\n",
      "* **What are you hoping to achieve by addressing these conflicts?** (Do you want to resolve them, understand them better, or just process your feelings about them?)\n",
      "\n",
      "Even just saying \"I'm struggling with a lot of complicated conflicts\" is a good start. I'm here to listen without judgment and offer whatever support I can. 😊\n",
      "Speaker_C: complex complex conflicts\n",
      "Gemma: It sounds like you're really grappling with a lot of complex conflicts. That takes a lot of emotional energy. It's understandable that you're using the word \"complex\" repeatedly – it really conveys the weight of the situation.\n",
      "\n",
      "To help me understand better and offer some support, could you tell me a little more about these conflicts? You don't have to go into detail if you don't want to, but even a few more words would be helpful. \n",
      "\n",
      "Perhaps:\n",
      "\n",
      "* **What *type* of conflicts are they?** (e.g., with a specific person, within a group, internal conflicts?)\n",
      "* **What's the biggest challenge about them?** (e.g., communication, finding solutions, emotional impact?)\n",
      "* **What's the overall feeling you're experiencing related to these conflicts?** (e.g., stressed, frustrated, hopeless?)\n",
      "\n",
      "Even just a brief summary would be a great starting point. I'm here to listen. 😊\n",
      "Speaker_C: existence\n",
      "Gemma: Okay. It sounds like you're grappling with questions about existence. That's a very profound and often complex area to explore. It's understandable that you're using the word \"complex\" to describe it. \n",
      "\n",
      "To help me understand what's on your mind and offer some support, could you tell me a little more about what aspects of existence are feeling particularly complex right now? \n",
      "\n",
      "Perhaps you could consider:\n",
      "\n",
      "* **What specifically about existence is causing you to feel this way?** (e.g., meaning, purpose, mortality, the universe, your place in it?)\n",
      "* **What thoughts or feelings are arising when you think about existence?** (e.g., anxiety, wonder, confusion, a sense of lack?)\n",
      "* **What are you hoping to understand or find through exploring these questions?** (e.g., meaning, peace, clarity?)\n",
      "\n",
      "Even just a few words about what's bringing this up would be a helpful starting point. I'm here to listen without judgment. 😊\n",
      "Speaker_C: exit\n",
      "--------------------------------------------------\n",
      "\n",
      "CONVERSATION_4:\n",
      "Session Feedback: True\n",
      "Session ID: session_20250805_144534_758\n",
      "Timestamp: 2025-08-05 14:45:34.758873\n",
      "Message Count: 9\n",
      "Full Text:\n",
      "Speaker_A: can you help me\n",
      "Gemma: Yes, I can! I'd love to help. To give you the best assistance, please tell me:\n",
      "\n",
      "* **What do you need help with?**  Be as specific as possible.  For example, instead of \"I need help with something,\" tell me \"I need help with a math problem,\" or \"I need help writing an email,\" or \"I need help understanding a concept.\"\n",
      "* **What have you tried already?**  This helps me avoid suggesting things you've already done.\n",
      "* **What is your goal?** What are you hoping to achieve by getting help?\n",
      "\n",
      "The more information you give me, the better I can assist you.  \n",
      "\n",
      "I can help with things like:\n",
      "\n",
      "* **Information gathering:**  Finding answers to your questions.\n",
      "* **Problem-solving:**  Breaking down complex problems into smaller steps.\n",
      "* **Writing:**  Drafting emails, stories, poems, etc.\n",
      "* **Brainstorming:**  Generating ideas.\n",
      "* **Coding:**  Providing code snippets (in various languages) and explaining them.\n",
      "* **Translation:**  Translating text between languages.\n",
      "* **Summarization:**  Condensing long texts into shorter versions.\n",
      "* **And much more!**\n",
      "\n",
      "\n",
      "\n",
      "Just let me know what's on your mind! 😊\n",
      "Speaker_A: what's the capital of france\n",
      "Gemma: The capital of France is **Paris**. \n",
      "\n",
      "Is there anything else you'd like to know about Paris, or perhaps another question you have? 😊\n",
      "Speaker_A: what's the capital of australia\n",
      "Gemma: The capital of Australia is **Canberra**. \n",
      "\n",
      "Is there anything else you'd like to know about Canberra, or perhaps another question you have? 😊\n",
      "Speaker_A: i have a complex question for you can you load your more powerful model\n",
      "Gemma: Okay! I understand you have a complex question and would like me to utilize my more powerful model. I'm ready. Please ask away! I'll do my best to provide a comprehensive and insightful answer. 😊 \n",
      "\n",
      "Just let me know what your complex question is. I'm excited to tackle it! ✨\n",
      "Speaker_A: exit\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the project root and add to Python path\n",
    "current_path = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if (parent / 'program_files').exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(\"Could not find project root directory\")\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from program_files.database.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "def get_gemma_conversations_with_feedback(days_back=1):\n",
    "    \"\"\"\n",
    "    Get conversations with Gemma from the last N days, grouped by session.\n",
    "    \n",
    "    Args:\n",
    "        days_back (int): Number of days to look back (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with conversation sessions as keys and metadata as values\n",
    "        Format: {\n",
    "            \"session_id\": {\n",
    "                \"session_feedback\": str,\n",
    "                \"full_text\": str,\n",
    "                \"timestamp\": datetime,\n",
    "                \"message_count\": int\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Initialize the database\n",
    "    db = EnhancedConversationDB()\n",
    "    \n",
    "    # Get all conversations with documents included\n",
    "    results = db.conversations.get(include=['metadatas', 'documents'])\n",
    "    \n",
    "    # Calculate date range\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=days_back)\n",
    "    \n",
    "    # Filter for date range and group by session\n",
    "    sessions = {}\n",
    "    \n",
    "    for i, metadata in enumerate(results['metadatas']):\n",
    "        timestamp_str = metadata.get('timestamp')\n",
    "        if not timestamp_str:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parse timestamp\n",
    "            conv_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')) if 'T' in timestamp_str else datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            # Check if within date range\n",
    "            if start_time <= conv_time <= end_time:\n",
    "                session_id = metadata.get('session_id')\n",
    "                if session_id not in sessions:\n",
    "                    sessions[session_id] = []\n",
    "                \n",
    "                sessions[session_id].append({\n",
    "                    'id': results['ids'][i],\n",
    "                    'text': results['documents'][i],\n",
    "                    'metadata': metadata,\n",
    "                    'timestamp': conv_time,\n",
    "                    'feedback_helpful': metadata.get('feedback_helpful', '')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamp {timestamp_str}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Filter sessions that contain Gemma conversations and build result\n",
    "    result_dict = {}\n",
    "    conversation_counter = 1\n",
    "    \n",
    "    for session_id, session_conversations in sessions.items():\n",
    "        # Check if this session has any Gemma conversations\n",
    "        has_gemma = any('[GEMMA]' in conv['text'] for conv in session_conversations)\n",
    "        \n",
    "        if not has_gemma:\n",
    "            continue  # Skip sessions without Gemma\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        session_conversations.sort(key=lambda x: x['timestamp'])\n",
    "        \n",
    "        # Get feedback for the session (use the first non-empty feedback found)\n",
    "        session_feedback = None\n",
    "        for conv in session_conversations:\n",
    "            if conv['feedback_helpful'] and conv['feedback_helpful'] != 'unknown':\n",
    "                session_feedback = conv['feedback_helpful']\n",
    "                break\n",
    "        \n",
    "        # Build full conversation text\n",
    "        conversation_lines = []\n",
    "        for conv in session_conversations:\n",
    "            # Extract just the speaker text (remove speaker/role prefix and [GEMMA] tag)\n",
    "            full_text = conv['text']\n",
    "            \n",
    "            # Remove the speaker/role prefix (e.g., \"Speaker_A (user): \")\n",
    "            if ': ' in full_text:\n",
    "                speaker_text = full_text.split(': ', 1)[1]\n",
    "            else:\n",
    "                speaker_text = full_text\n",
    "            \n",
    "            # Remove [GEMMA] tag if present\n",
    "            speaker_text = speaker_text.replace(' [GEMMA]', '')\n",
    "            \n",
    "            # Add speaker name and text\n",
    "            speaker = conv['metadata'].get('speaker', 'Unknown')\n",
    "            conversation_lines.append(f\"{speaker}: {speaker_text}\")\n",
    "        \n",
    "        full_text = \"\\n\".join(conversation_lines)\n",
    "        \n",
    "        # Add to result dictionary\n",
    "        result_dict[f\"conversation_{conversation_counter}\"] = {\n",
    "            \"session_feedback\": session_feedback,\n",
    "            \"full_text\": full_text,\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp\": session_conversations[0]['timestamp'],\n",
    "            \"message_count\": len(session_conversations)\n",
    "        }\n",
    "        \n",
    "        conversation_counter += 1\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Example usage:\n",
    "conversations = get_gemma_conversations_with_feedback(days_back=1)\n",
    "\n",
    "# Display the results\n",
    "for conv_key, conv_data in conversations.items():\n",
    "    print(f\"\\n{conv_key.upper()}:\")\n",
    "    print(f\"Session Feedback: {conv_data['session_feedback']}\")\n",
    "    print(f\"Session ID: {conv_data['session_id']}\")\n",
    "    print(f\"Timestamp: {conv_data['timestamp']}\")\n",
    "    print(f\"Message Count: {conv_data['message_count']}\")\n",
    "    print(f\"Full Text:\\n{conv_data['full_text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eded3328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_1': {'session_feedback': 'True',\n",
       "  'full_text': \"Speaker_A: can you help me\\nGemma: Yes, I can definitely try! 😊\\n\\nPlease tell me what you need help with. The more information you can give me, the better I can assist you.  For example:\\n\\n* **What are you trying to do?** (e.g., write an email, solve a math problem, find information, brainstorm ideas)\\n* **What's the problem you're encountering?** (e.g., I don't know where to start, I'm getting an error message, I'm stuck on a specific step)\\n* **What have you tried already?** (This helps me avoid suggesting things you've already done.)\\n* **What kind of help are you looking for?** (e.g., guidance, suggestions, code, explanations)\\n\\nI'm here to help in any way I can. Just let me know what's on your mind!\\nSpeaker_A: what is your name\\nGemma: As a large language model, I don't have a name in the traditional sense. I was created by the Gemma team at Google DeepMind. You can think of me as an open-weights AI assistant! I'm here to help you with a variety of tasks. 😊\\nSpeaker_A: exit\",\n",
       "  'session_id': 'session_20250805_115307_390',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 11, 53, 7, 390773),\n",
       "  'message_count': 5},\n",
       " 'conversation_2': {'session_feedback': None,\n",
       "  'full_text': \"Speaker_A: how are you going\\nGemma: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I'm functioning optimally and ready to assist you. \\n\\nHow are *you* doing today? I hope you're having a good one! Is there anything I can help you with? 😊\\nSpeaker_A: i'm very happy i guess\\nGemma: That's wonderful to hear! I'm so glad you're feeling happy today. 😊 It's always nice to hear that things are going well. \\n\\nIs there anything specific that's making you happy, or is there anything I can do to help make your day even better? I'm here for you! ✨\\nSpeaker_B: i'm thinking some complex thoughts\\nGemma: That sounds fascinating! Complex thoughts can be really stimulating. 😊 What kind of thoughts are you exploring? Sometimes just verbalizing them can help clarify them. \\n\\nWould you like to talk about them? I can offer a different perspective, help you break them down, or just listen if you need a space to think. No pressure at all! ✨\\nSpeaker_E: complex complex complex complex complex\\nGemma: Okay, it sounds like you're really delving into some intricate ideas! That's a powerful thing to do. ✨ It's perfectly alright to just have a lot of complex thoughts swirling around. \\n\\nIt seems like you're feeling quite immersed in them. Do any of those thoughts feel particularly overwhelming right now? Or are you trying to untangle a specific aspect of them? \\n\\nJust letting those thoughts exist is a good first step. If you'd like to explore any of them further, or if you'd like me to help you break them down in any way, please feel free to share. I'm here to listen without judgment. 😊\\nSpeaker_D: complexity\",\n",
       "  'session_id': 'session_20250805_141311_767',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 13, 11, 767110),\n",
       "  'message_count': 9},\n",
       " 'conversation_3': {'session_feedback': 'True',\n",
       "  'full_text': 'Gemma: Okay! That\\'s great to hear.  Who helped you?  Knowing who helped you might help me understand the situation better. \\n\\nTo help me respond in a useful way, you could tell me:\\n\\n* **Who helped you?** (A person, an animal, a program, etc.)\\n* **What did they help you with?** (A problem, a task, a feeling, etc.)\\n* **How did it make you feel?** (Relieved, grateful, happy, etc.)\\n\\nEven just saying \"Someone helped me with a difficult problem\" is a good start. 😊\\nSpeaker_C: complex complex complex complex complex complex complex\\nGemma: Okay! I see you\\'re indicating a feeling of being overwhelmed with \"complex\" things. It sounds like you\\'re experiencing a lot of complexity right now. \\n\\nTo help me understand and offer support, could you tell me a little more about what\\'s making things feel so complex? \\n\\n* **Who or what is contributing to this complexity?** (Is it a task, a situation, a feeling?)\\n* **What specifically is making it feel complex?** (Is it the number of parts, the difficulty of the task, the emotional weight?)\\n* **How is this complexity affecting you?** (Are you feeling stressed, frustrated, confused?)\\n\\nEven just saying \"I\\'m feeling overwhelmed by a lot of complicated things\" is a good start. 😊  I\\'m here to listen and help in any way I can.\\nSpeaker_C: let\\'s complex complex complex complex complex complex conflicts\\nGemma: Okay, it sounds like you\\'re feeling overwhelmed by conflicts. That\\'s a really difficult situation to be in. It\\'s completely understandable to feel complex and overwhelmed when dealing with conflicts. \\n\\nTo help me understand what\\'s going on and how I can support you, could you tell me a little more about the conflicts you\\'re dealing with? \\n\\n* **What kind of conflicts are these?** (Are they personal, professional, family-related, etc.?)\\n* **What\\'s making them feel so complex?** (Are there many parties involved, are the issues deeply rooted, are they emotionally charged?)\\n* **What are you hoping to achieve by addressing these conflicts?** (Do you want to resolve them, understand them better, or just process your feelings about them?)\\n\\nEven just saying \"I\\'m struggling with a lot of complicated conflicts\" is a good start. I\\'m here to listen without judgment and offer whatever support I can. 😊\\nSpeaker_C: complex complex conflicts\\nGemma: It sounds like you\\'re really grappling with a lot of complex conflicts. That takes a lot of emotional energy. It\\'s understandable that you\\'re using the word \"complex\" repeatedly – it really conveys the weight of the situation.\\n\\nTo help me understand better and offer some support, could you tell me a little more about these conflicts? You don\\'t have to go into detail if you don\\'t want to, but even a few more words would be helpful. \\n\\nPerhaps:\\n\\n* **What *type* of conflicts are they?** (e.g., with a specific person, within a group, internal conflicts?)\\n* **What\\'s the biggest challenge about them?** (e.g., communication, finding solutions, emotional impact?)\\n* **What\\'s the overall feeling you\\'re experiencing related to these conflicts?** (e.g., stressed, frustrated, hopeless?)\\n\\nEven just a brief summary would be a great starting point. I\\'m here to listen. 😊\\nSpeaker_C: existence\\nGemma: Okay. It sounds like you\\'re grappling with questions about existence. That\\'s a very profound and often complex area to explore. It\\'s understandable that you\\'re using the word \"complex\" to describe it. \\n\\nTo help me understand what\\'s on your mind and offer some support, could you tell me a little more about what aspects of existence are feeling particularly complex right now? \\n\\nPerhaps you could consider:\\n\\n* **What specifically about existence is causing you to feel this way?** (e.g., meaning, purpose, mortality, the universe, your place in it?)\\n* **What thoughts or feelings are arising when you think about existence?** (e.g., anxiety, wonder, confusion, a sense of lack?)\\n* **What are you hoping to understand or find through exploring these questions?** (e.g., meaning, peace, clarity?)\\n\\nEven just a few words about what\\'s bringing this up would be a helpful starting point. I\\'m here to listen without judgment. 😊\\nSpeaker_C: exit',\n",
       "  'session_id': 'session_20250805_142101_563',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 21, 4, 135471),\n",
       "  'message_count': 10},\n",
       " 'conversation_4': {'session_feedback': 'True',\n",
       "  'full_text': 'Speaker_A: can you help me\\nGemma: Yes, I can! I\\'d love to help. To give you the best assistance, please tell me:\\n\\n* **What do you need help with?**  Be as specific as possible.  For example, instead of \"I need help with something,\" tell me \"I need help with a math problem,\" or \"I need help writing an email,\" or \"I need help understanding a concept.\"\\n* **What have you tried already?**  This helps me avoid suggesting things you\\'ve already done.\\n* **What is your goal?** What are you hoping to achieve by getting help?\\n\\nThe more information you give me, the better I can assist you.  \\n\\nI can help with things like:\\n\\n* **Information gathering:**  Finding answers to your questions.\\n* **Problem-solving:**  Breaking down complex problems into smaller steps.\\n* **Writing:**  Drafting emails, stories, poems, etc.\\n* **Brainstorming:**  Generating ideas.\\n* **Coding:**  Providing code snippets (in various languages) and explaining them.\\n* **Translation:**  Translating text between languages.\\n* **Summarization:**  Condensing long texts into shorter versions.\\n* **And much more!**\\n\\n\\n\\nJust let me know what\\'s on your mind! 😊\\nSpeaker_A: what\\'s the capital of france\\nGemma: The capital of France is **Paris**. \\n\\nIs there anything else you\\'d like to know about Paris, or perhaps another question you have? 😊\\nSpeaker_A: what\\'s the capital of australia\\nGemma: The capital of Australia is **Canberra**. \\n\\nIs there anything else you\\'d like to know about Canberra, or perhaps another question you have? 😊\\nSpeaker_A: i have a complex question for you can you load your more powerful model\\nGemma: Okay! I understand you have a complex question and would like me to utilize my more powerful model. I\\'m ready. Please ask away! I\\'ll do my best to provide a comprehensive and insightful answer. 😊 \\n\\nJust let me know what your complex question is. I\\'m excited to tackle it! ✨\\nSpeaker_A: exit',\n",
       "  'session_id': 'session_20250805_144534_758',\n",
       "  'timestamp': datetime.datetime(2025, 8, 5, 14, 45, 34, 758873),\n",
       "  'message_count': 9}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48fafaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to conversations.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('conversations.json', 'w') as f:\n",
    "    json.dump(conversations, f, indent=4, default=str)\n",
    "print(f\"✅ Saved to conversations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03febb43",
   "metadata": {},
   "source": [
    "# ML Clustering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd766bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 ML CLUSTERING SYSTEM TEST\n",
      "==================================================\n",
      "✅ Initial Clustering State:\n",
      "   Is clustered: False\n",
      "✅ Generated Test Data:\n",
      "   Total samples: 16\n",
      "   Male samples: 8\n",
      "   Female samples: 8\n",
      "   Feature dimensions: 14\n",
      "\n",
      "�� Testing K-means Clustering...\n",
      "✅ Clustering Successful!\n",
      "   Clusters: 2\n",
      "   Samples: 16\n",
      "   Silhouette score: 0.187\n",
      "   Method: kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpeakerClustering' object has no attribute 'identify_speaker_from_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Test speaker identification\u001b[39;00m\n\u001b[32m     95\u001b[39m test_features = {\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33menergy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1300.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpitch_estimate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m110.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzero_crossings\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m38\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspectral_centroid\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m650.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_variance\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m160.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpeak_amplitude\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2600.0\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrms_energy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1050.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.22\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_3\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.12\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformant_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m420.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mformant_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1250.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjitter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.019\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshimmer\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.026\u001b[39m\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m speaker_name, confidence = \u001b[43mclustering\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_speaker_from_features\u001b[49m(test_features)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Speaker Identification Test:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Identified speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpeakerClustering' object has no attribute 'identify_speaker_from_features'"
     ]
    }
   ],
   "source": [
    "# Test 2: ML Clustering System Verification\n",
    "\n",
    "print(\"🧪 ML CLUSTERING SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test ML clustering system\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "clustering = SpeakerClustering()\n",
    "\n",
    "# Check initial state\n",
    "initial_stats = clustering.get_clustering_stats()\n",
    "print(f\"✅ Initial Clustering State:\")\n",
    "print(f\"   Is clustered: {initial_stats['is_clustered']}\")\n",
    "\n",
    "# Create synthetic training data\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic audio features for testing\n",
    "def generate_synthetic_features(speaker_type=\"male\", num_samples=5):\n",
    "    \"\"\"Generate synthetic audio features for testing\"\"\"\n",
    "    features_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    base_features = {\n",
    "        'male': {\n",
    "            'energy': 1200.0, 'pitch_estimate': 100.0, 'formant_1': 400.0\n",
    "        },\n",
    "        'female': {\n",
    "            'energy': 2000.0, 'pitch_estimate': 180.0, 'formant_1': 600.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base = base_features[speaker_type]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Add some variation\n",
    "        features = {\n",
    "            'energy': base['energy'] + np.random.normal(0, 100),\n",
    "            'pitch_estimate': base['pitch_estimate'] + np.random.normal(0, 10),\n",
    "            'zero_crossings': 35 + np.random.normal(0, 5),\n",
    "            'spectral_centroid': 600 + np.random.normal(0, 50),\n",
    "            'energy_variance': 150 + np.random.normal(0, 20),\n",
    "            'peak_amplitude': 2500 + np.random.normal(0, 200),\n",
    "            'rms_energy': 1000 + np.random.normal(0, 100),\n",
    "            'mfcc_1': 0.3 + np.random.normal(0, 0.05),\n",
    "            'mfcc_2': 0.2 + np.random.normal(0, 0.05),\n",
    "            'mfcc_3': 0.1 + np.random.normal(0, 0.05),\n",
    "            'formant_1': base['formant_1'] + np.random.normal(0, 20),\n",
    "            'formant_2': 1200 + np.random.normal(0, 50),\n",
    "            'jitter': 0.018 + np.random.normal(0, 0.005),\n",
    "            'shimmer': 0.025 + np.random.normal(0, 0.005)\n",
    "        }\n",
    "        \n",
    "        features_list.append(list(features.values()))\n",
    "        metadata_list.append({\n",
    "            'conversation_id': f'test_conv_{speaker_type}_{i}',\n",
    "            'session_id': f'test_session_{speaker_type}',\n",
    "            'speaker': f'{speaker_type.capitalize()}Speaker',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'feature_count': 14\n",
    "        })\n",
    "    \n",
    "    return features_list, metadata_list\n",
    "\n",
    "# Generate test data\n",
    "male_features, male_metadata = generate_synthetic_features(\"male\", 8)\n",
    "female_features, female_metadata = generate_synthetic_features(\"female\", 8)\n",
    "\n",
    "# Combine all features\n",
    "all_features = male_features + female_features\n",
    "all_metadata = male_metadata + female_metadata\n",
    "\n",
    "print(f\"✅ Generated Test Data:\")\n",
    "print(f\"   Total samples: {len(all_features)}\")\n",
    "print(f\"   Male samples: {len(male_features)}\")\n",
    "print(f\"   Female samples: {len(female_features)}\")\n",
    "print(f\"   Feature dimensions: {len(all_features[0])}\")\n",
    "\n",
    "# Test clustering\n",
    "print(f\"\\n�� Testing K-means Clustering...\")\n",
    "result = clustering.perform_clustering(\n",
    "    all_features, all_metadata,\n",
    "    method='kmeans',\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"✅ Clustering Successful!\")\n",
    "    print(f\"   Clusters: {result['n_clusters']}\")\n",
    "    print(f\"   Samples: {result['n_samples']}\")\n",
    "    print(f\"   Silhouette score: {result['silhouette_score']:.3f}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    \n",
    "    # Test speaker identification\n",
    "    test_features = {\n",
    "        'energy': 1300.0, 'pitch_estimate': 110.0, 'zero_crossings': 38,\n",
    "        'spectral_centroid': 650.0, 'energy_variance': 160.0, 'peak_amplitude': 2600.0,\n",
    "        'rms_energy': 1050.0, 'mfcc_1': 0.32, 'mfcc_2': 0.22, 'mfcc_3': 0.12,\n",
    "        'formant_1': 420.0, 'formant_2': 1250.0, 'jitter': 0.019, 'shimmer': 0.026\n",
    "    }\n",
    "    \n",
    "    speaker_name, confidence = clustering.identify_speaker_from_features(test_features)\n",
    "    print(f\"✅ Speaker Identification Test:\")\n",
    "    print(f\"   Identified speaker: {speaker_name}\")\n",
    "    print(f\"   Confidence: {confidence:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Clustering failed: {result.get('reason', 'unknown')}\")\n",
    "\n",
    "print(\"🎉 ML clustering system is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration test\n",
    "\n",
    "# Test 3: Database + ML Integration Test\n",
    "print(\"🧪 INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the complete pipeline\n",
    "from speech.speech_processor import SpeakerDetector\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "\n",
    "# Initialize components\n",
    "db = EnhancedConversationDB()\n",
    "clustering = SpeakerClustering()\n",
    "speaker_detector = SpeakerDetector(\n",
    "    enhanced_db=db,\n",
    "    speaker_clustering=clustering\n",
    ")\n",
    "\n",
    "print(f\"✅ Components Initialized:\")\n",
    "print(f\"   Database: {type(db).__name__}\")\n",
    "print(f\"   Clustering: {type(clustering).__name__}\")\n",
    "print(f\"   Speaker Detector: {type(speaker_detector).__name__}\")\n",
    "\n",
    "# Test speaker detection with ML\n",
    "import numpy as np\n",
    "\n",
    "# Simulate audio processing\n",
    "dummy_audio = np.random.randint(-1000, 1000, size=2048, dtype=np.int16).tobytes()\n",
    "\n",
    "print(f\"\\n🔧 Testing Speaker Detection with ML:\")\n",
    "print(f\"   Initial speaker: {speaker_detector.current_speaker}\")\n",
    "\n",
    "# Process multiple audio frames to build up features\n",
    "for i in range(10):\n",
    "    speaker_detector.update_speaker_count(dummy_audio, 0)\n",
    "\n",
    "print(f\"   After processing: {speaker_detector.current_speaker}\")\n",
    "print(f\"   Speaker changes: {speaker_detector.speaker_changes}\")\n",
    "print(f\"   Feature buffer size: {len(speaker_detector.feature_buffer)}\")\n",
    "\n",
    "# Test feature extraction\n",
    "current_features = speaker_detector.get_current_features()\n",
    "print(f\"   Current features available: {current_features is not None}\")\n",
    "if current_features:\n",
    "    print(f\"   Feature count: {len(current_features)}\")\n",
    "\n",
    "# Test database integration\n",
    "if current_features:\n",
    "    # Add to database\n",
    "    db.add_conversation_with_audio(\n",
    "        session_id=\"integration_test\",\n",
    "        text=\"Integration test conversation\",\n",
    "        speaker=speaker_detector.current_speaker,\n",
    "        role=\"user\",\n",
    "        is_gemma_mode=False,\n",
    "        audio_features=current_features\n",
    "    )\n",
    "    \n",
    "    # Verify storage\n",
    "    stats = db.get_conversation_stats()\n",
    "    print(f\"✅ Database Integration:\")\n",
    "    print(f\"   Total conversations: {stats['total_conversations']}\")\n",
    "    print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "\n",
    "print(\"🎉 Integration test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee07c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline test\n",
    "\n",
    "# Test 4: Training Pipeline Test\n",
    "print(\"🧪 TRAINING PIPELINE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the training script functionality\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the tests directory to path\n",
    "sys.path.append('tests')\n",
    "\n",
    "# Import the training function\n",
    "from train_unsupervised_speakers_new import train_unsupervised_speakers, analyze_clustering_quality\n",
    "\n",
    "print(\"✅ Training functions imported successfully\")\n",
    "\n",
    "# Check if we have enough data for training\n",
    "stats = db.get_conversation_stats()\n",
    "print(f\"📊 Current Data Status:\")\n",
    "print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "print(f\"   Need for training: 10+\")\n",
    "\n",
    "if stats['total_audio_features'] >= 10:\n",
    "    print(\"✅ Sufficient data for training!\")\n",
    "    print(\"   Run: train_unsupervised_speakers() to train clustering\")\n",
    "else:\n",
    "    print(\"⏳ Need more data for training\")\n",
    "    print(\"   Continue using the system to collect more audio features\")\n",
    "\n",
    "# Test analysis function\n",
    "print(f\"\\n🔍 Testing Analysis Function:\")\n",
    "try:\n",
    "    analyze_clustering_quality()\n",
    "    print(\"✅ Analysis function works!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Analysis function error: {e}\")\n",
    "\n",
    "print(\"🎉 Training pipeline test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5a272",
   "metadata": {},
   "source": [
    "# Delete database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ba66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Old database deleted - ready for 14-feature data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"✅ Old database deleted - ready for 14-feature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f399dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database cleared for fresh start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedConversationDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Database cleared for fresh start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create completely fresh database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m db = \u001b[43mEnhancedConversationDB\u001b[49m()\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Fresh database ready\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EnhancedConversationDB' is not defined"
     ]
    }
   ],
   "source": [
    "# Final database clear\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"✅ Database cleared for fresh start\")\n",
    "\n",
    "# Create completely fresh database\n",
    "db = EnhancedConversationDB()\n",
    "print(\"✅ Fresh database ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layout_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
