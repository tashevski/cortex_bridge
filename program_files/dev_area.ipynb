{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d774e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database inspector loaded\n"
     ]
    }
   ],
   "source": [
    "# Database Inspector\n",
    "# Inspect database contents and test get_data/update_by_indexes functions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "print(\"‚úÖ Database inspector loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea7b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Database Statistics:\n",
      "  total_conversations: 27\n",
      "  total_audio_features: 27\n",
      "  conversations_with_audio: 27\n",
      "\n",
      "üìà Audio coverage: 27/27 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Database Overview\n",
    "db = EnhancedConversationDB()\n",
    "stats = db.get_conversation_stats()\n",
    "\n",
    "print(\"üìä Database Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìà Audio coverage: {stats['conversations_with_audio']}/{stats['total_conversations']} ({stats['conversations_with_audio']/max(stats['total_conversations'],1)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6f4443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Audio Features: 27 samples\n",
      "\n",
      "üìè Feature dimensions: {9: 27}\n",
      "\n",
      "üîç Sample features (first 3):\n",
      "  Sample 0: 9D - [133.470703125, 168.15994262695312, 0.13678553700447083]... | Speaker: Speaker I\n",
      "  Sample 1: 9D - [24.6630859375, 30.28441047668457, 0.02589154802262783]... | Speaker: Speaker R\n",
      "  Sample 2: 9D - [344.06787109375, 407.9437255859375, 0.20420126616954803]... | Speaker: Speaker H\n",
      "\n",
      "üìù Feature names: ['energy', 'rms_energy', 'zcr', 'spectral_centroid', 'spectral_rolloff', 'pitch', 'mfcc1', 'mfcc2', 'mfcc3']\n"
     ]
    }
   ],
   "source": [
    "# Audio Features Inspection\n",
    "# Get all audio features using the general get_data function\n",
    "features, metadata = db.get_data(\"audio_features\", return_features=True)\n",
    "\n",
    "print(f\"üéµ Audio Features: {len(features)} samples\")\n",
    "\n",
    "if len(features) > 0:\n",
    "    # Check dimensions\n",
    "    dimensions = [len(f) for f in features]\n",
    "    dim_counts = Counter(dimensions)\n",
    "    print(f\"\\nüìè Feature dimensions: {dict(dim_counts)}\")\n",
    "    \n",
    "    # Show sample features\n",
    "    print(f\"\\nüîç Sample features (first 3):\")\n",
    "    for i, (feat, meta) in enumerate(zip(features[:3], metadata[:3])):\n",
    "        print(f\"  Sample {i}: {len(feat)}D - {feat[:3]}... | Speaker: {meta.get('speaker', 'Unknown')}\")\n",
    "    \n",
    "    # Get feature names from raw document\n",
    "    raw_data = db.audio_features.get()\n",
    "    if raw_data['documents']:\n",
    "        latest_doc = json.loads(raw_data['documents'][-1])\n",
    "        print(f\"\\nüìù Feature names: {latest_doc.get('feature_names', 'Not available')}\")\n",
    "else:\n",
    "    print(\"No audio features found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6f009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2025-08-04T18:00:56.641535',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180056_536824',\n",
       "  'speaker': 'Speaker I',\n",
       "  'ml_speaker': 'C',\n",
       "  'test_field': 'test_value_updated',\n",
       "  'gmm_speaker': 'C',\n",
       "  'test_number': 42.5,\n",
       "  'gmm_confidence': 0.9999999999999992,\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'ml_speaker_confidence': 0.9999999999999992},\n",
       " {'ml_speaker_confidence': 1.0,\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'gmm_speaker': 'D',\n",
       "  'timestamp': '2025-08-04T18:01:02.088907',\n",
       "  'ml_speaker': 'D',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180102_008583',\n",
       "  'speaker': 'Speaker R'},\n",
       " {'session_id': 'session_20250804_180050_295',\n",
       "  'speaker': 'Speaker H',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'timestamp': '2025-08-04T18:01:06.715642',\n",
       "  'gmm_speaker': 'K',\n",
       "  'ml_speaker': 'K',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180106_641743'},\n",
       " {'gmm_speaker': 'D',\n",
       "  'speaker': 'Speaker J',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180108_530490',\n",
       "  'ml_speaker': 'D',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'timestamp': '2025-08-04T18:01:08.609743',\n",
       "  'gmm_confidence': 1.0},\n",
       " {'timestamp': '2025-08-04T18:01:12.838449',\n",
       "  'speaker': 'Speaker Q',\n",
       "  'ml_speaker': 'L',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'gmm_speaker': 'L',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180112_756390'},\n",
       " {'conversation_id': 'session_20250804_180050_295_20250804_180118_278265',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'speaker': 'Speaker K',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'gmm_confidence': 1.0,\n",
       "  'timestamp': '2025-08-04T18:01:18.351213',\n",
       "  'gmm_speaker': 'C',\n",
       "  'ml_speaker': 'C'},\n",
       " {'session_id': 'session_20250804_180050_295',\n",
       "  'ml_speaker': 'E',\n",
       "  'speaker': 'Speaker N',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'timestamp': '2025-08-04T18:01:20.764687',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180120_688694',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'gmm_speaker': 'E'},\n",
       " {'timestamp': '2025-08-04T18:01:25.110109',\n",
       "  'ml_speaker_confidence': 0.9999999999999998,\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180125_036934',\n",
       "  'speaker': 'Speaker D',\n",
       "  'gmm_speaker': 'K',\n",
       "  'ml_speaker': 'K',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'gmm_confidence': 0.9999999999999998},\n",
       " {'ml_speaker': 'A',\n",
       "  'gmm_speaker': 'A',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180127_475933',\n",
       "  'timestamp': '2025-08-04T18:01:27.552487',\n",
       "  'speaker': 'Speaker H',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'ml_speaker_confidence': 1.0},\n",
       " {'timestamp': '2025-08-04T18:01:32.036600',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'ml_speaker': 'C',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'gmm_speaker': 'C',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180131_959369',\n",
       "  'speaker': 'Speaker W'},\n",
       " {'session_id': 'session_20250804_180050_295',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'gmm_speaker': 'A',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180134_904828',\n",
       "  'ml_speaker': 'A',\n",
       "  'timestamp': '2025-08-04T18:01:34.979488',\n",
       "  'speaker': 'Speaker E'},\n",
       " {'ml_speaker_confidence': 0.999999999999989,\n",
       "  'gmm_speaker': 'C',\n",
       "  'speaker': 'Speaker O',\n",
       "  'timestamp': '2025-08-04T18:01:39.461429',\n",
       "  'gmm_confidence': 0.999999999999989,\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180139_385514',\n",
       "  'ml_speaker': 'C',\n",
       "  'session_id': 'session_20250804_180050_295'},\n",
       " {'gmm_confidence': 1.0,\n",
       "  'ml_speaker': 'G',\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180142_580923',\n",
       "  'timestamp': '2025-08-04T18:01:42.656833',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'gmm_speaker': 'G',\n",
       "  'speaker': 'Speaker U'},\n",
       " {'ml_speaker_confidence': 1.0,\n",
       "  'timestamp': '2025-08-04T18:01:47.147658',\n",
       "  'conversation_id': 'session_20250804_180050_295_20250804_180147_064885',\n",
       "  'ml_speaker': 'M',\n",
       "  'gmm_speaker': 'M',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'speaker': 'Speaker I'},\n",
       " {'conversation_id': 'session_20250804_180050_295_20250804_180150_902422',\n",
       "  'timestamp': '2025-08-04T18:01:50.973402',\n",
       "  'gmm_speaker': 'H',\n",
       "  'speaker': 'Speaker U',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'session_id': 'session_20250804_180050_295',\n",
       "  'ml_speaker': 'H',\n",
       "  'gmm_confidence': 1.0},\n",
       " {'ml_speaker_confidence': 0.9999999999999944,\n",
       "  'session_id': 'realistic_test_0',\n",
       "  'speaker': 'Speaker_0',\n",
       "  'ml_speaker': 'I',\n",
       "  'gmm_confidence': 0.9999999999999944,\n",
       "  'timestamp': '2025-08-04T18:49:35.113806',\n",
       "  'gmm_speaker': 'I',\n",
       "  'conversation_id': 'realistic_test_0_20250804_184935_031109'},\n",
       " {'gmm_speaker': 'B',\n",
       "  'conversation_id': 'realistic_test_1_20250804_184935_177221',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'session_id': 'realistic_test_1',\n",
       "  'ml_speaker': 'B',\n",
       "  'speaker': 'Speaker_1',\n",
       "  'timestamp': '2025-08-04T18:49:35.230867'},\n",
       " {'session_id': 'realistic_test_2',\n",
       "  'gmm_confidence': 0.9999999999897398,\n",
       "  'ml_speaker_confidence': 0.9999999999897398,\n",
       "  'speaker': 'Speaker_2',\n",
       "  'ml_speaker': 'B',\n",
       "  'conversation_id': 'realistic_test_2_20250804_184935_287970',\n",
       "  'timestamp': '2025-08-04T18:49:35.345434',\n",
       "  'gmm_speaker': 'B'},\n",
       " {'session_id': 'realistic_test_3',\n",
       "  'ml_speaker': 'I',\n",
       "  'speaker': 'Speaker_0',\n",
       "  'timestamp': '2025-08-04T18:49:35.457816',\n",
       "  'gmm_confidence': 0.9999999999999768,\n",
       "  'gmm_speaker': 'I',\n",
       "  'ml_speaker_confidence': 0.9999999999999768,\n",
       "  'conversation_id': 'realistic_test_3_20250804_184935_401953'},\n",
       " {'speaker': 'Speaker_1',\n",
       "  'timestamp': '2025-08-04T18:49:35.568601',\n",
       "  'ml_speaker': 'I',\n",
       "  'session_id': 'realistic_test_4',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'conversation_id': 'realistic_test_4_20250804_184935_514186',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'gmm_speaker': 'I'},\n",
       " {'speaker': 'Speaker_2',\n",
       "  'timestamp': '2025-08-04T18:49:35.683657',\n",
       "  'ml_speaker': 'I',\n",
       "  'gmm_confidence': 0.9999999999832516,\n",
       "  'conversation_id': 'realistic_test_5_20250804_184935_626466',\n",
       "  'ml_speaker_confidence': 0.9999999999832516,\n",
       "  'gmm_speaker': 'I',\n",
       "  'session_id': 'realistic_test_5'},\n",
       " {'gmm_confidence': 1.0,\n",
       "  'speaker': 'Speaker_0',\n",
       "  'timestamp': '2025-08-04T18:49:35.797717',\n",
       "  'gmm_speaker': 'K',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'conversation_id': 'realistic_test_6_20250804_184935_741279',\n",
       "  'session_id': 'realistic_test_6',\n",
       "  'ml_speaker': 'K'},\n",
       " {'speaker': 'Speaker_1',\n",
       "  'timestamp': '2025-08-04T18:49:35.913701',\n",
       "  'conversation_id': 'realistic_test_7_20250804_184935_856002',\n",
       "  'gmm_confidence': 0.9964796554442974,\n",
       "  'ml_speaker_confidence': 0.9964796554442974,\n",
       "  'ml_speaker': 'F',\n",
       "  'gmm_speaker': 'F',\n",
       "  'session_id': 'realistic_test_7'},\n",
       " {'conversation_id': 'realistic_test_8_20250804_184935_969665',\n",
       "  'gmm_speaker': 'I',\n",
       "  'ml_speaker_confidence': 0.999999977919176,\n",
       "  'gmm_confidence': 0.999999977919176,\n",
       "  'ml_speaker': 'I',\n",
       "  'timestamp': '2025-08-04T18:49:36.026739',\n",
       "  'speaker': 'Speaker_2',\n",
       "  'session_id': 'realistic_test_8'},\n",
       " {'gmm_speaker': 'J',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'timestamp': '2025-08-04T18:49:36.144106',\n",
       "  'speaker': 'Speaker_0',\n",
       "  'ml_speaker': 'J',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'session_id': 'realistic_test_9',\n",
       "  'conversation_id': 'realistic_test_9_20250804_184936_084465'},\n",
       " {'timestamp': '2025-08-04T18:49:36.259107',\n",
       "  'ml_speaker_confidence': 1.0,\n",
       "  'ml_speaker': 'F',\n",
       "  'conversation_id': 'realistic_test_10_20250804_184936_200624',\n",
       "  'session_id': 'realistic_test_10',\n",
       "  'gmm_confidence': 1.0,\n",
       "  'gmm_speaker': 'F',\n",
       "  'speaker': 'Speaker_1'},\n",
       " {'ml_speaker': 'I',\n",
       "  'timestamp': '2025-08-04T18:49:36.377062',\n",
       "  'speaker': 'Speaker_2',\n",
       "  'ml_speaker_confidence': 0.9999999795660512,\n",
       "  'conversation_id': 'realistic_test_11_20250804_184936_317223',\n",
       "  'gmm_speaker': 'I',\n",
       "  'session_id': 'realistic_test_11',\n",
       "  'gmm_confidence': 0.9999999795660512}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7gg510gli34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing get_data function:\n",
      "‚úÖ Audio features (return_features=True): 15 samples\n",
      "   Sample type: <class 'list'> with 9 values\n",
      "‚úÖ Audio features (return_features=False): 15 documents\n",
      "   Sample type: <class 'str'> (JSON string)\n",
      "‚úÖ Conversations: 15 documents\n",
      "   Sample: 'Speaker I (user): the two friends...'\n",
      "\n",
      "üéØ get_data function works correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test get_data Function\n",
    "print(\"üß™ Testing get_data function:\")\n",
    "\n",
    "# Test 1: Audio features with features=True\n",
    "features1, meta1 = db.get_data(\"audio_features\", return_features=True)\n",
    "print(f\"‚úÖ Audio features (return_features=True): {len(features1)} samples\")\n",
    "if len(features1) > 0:\n",
    "    print(f\"   Sample type: {type(features1[0])} with {len(features1[0])} values\")\n",
    "\n",
    "# Test 2: Audio features with features=False (raw documents)\n",
    "docs1, meta2 = db.get_data(\"audio_features\", return_features=False)\n",
    "print(f\"‚úÖ Audio features (return_features=False): {len(docs1)} documents\")\n",
    "if len(docs1) > 0:\n",
    "    print(f\"   Sample type: {type(docs1[0])} (JSON string)\")\n",
    "\n",
    "# Test 3: Conversations\n",
    "docs2, meta3 = db.get_data(\"conversations\", return_features=False)\n",
    "print(f\"‚úÖ Conversations: {len(docs2)} documents\")\n",
    "if len(docs2) > 0:\n",
    "    print(f\"   Sample: '{docs2[0][:50]}...'\")\n",
    "\n",
    "print(\"\\nüéØ get_data function works correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ex3ti16q1qf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing update_by_indexes function:\n",
      "üìù Updating index 0 with: {'test_field': 'test_value_updated', 'test_number': 42.5}\n",
      "‚úÖ Updated 1 entries\n",
      "üîç Verification - Index 0 metadata:\n",
      "   test_field: test_value_updated\n",
      "   test_number: 42.5\n",
      "   speaker: Speaker I\n",
      "‚úÖ update_by_indexes works correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test update_by_indexes Function\n",
    "print(\"üß™ Testing update_by_indexes function:\")\n",
    "\n",
    "# Test update on audio features\n",
    "if len(features) > 0:\n",
    "    # Add a test field to first sample\n",
    "    test_updates = {\n",
    "        0: {'test_field': 'test_value_updated', 'test_number': 42.5}\n",
    "    }\n",
    "    \n",
    "    print(f\"üìù Updating index 0 with: {test_updates[0]}\")\n",
    "    updated_count = db.update_by_indexes(test_updates, \"audio_features\")\n",
    "    print(f\"‚úÖ Updated {updated_count} entries\")\n",
    "    \n",
    "    # Verify the update\n",
    "    _, updated_meta = db.get_data(\"audio_features\", return_features=True)\n",
    "    if len(updated_meta) > 0:\n",
    "        first_meta = updated_meta[0]\n",
    "        print(f\"üîç Verification - Index 0 metadata:\")\n",
    "        print(f\"   test_field: {first_meta.get('test_field', 'NOT FOUND')}\")\n",
    "        print(f\"   test_number: {first_meta.get('test_number', 'NOT FOUND')}\")\n",
    "        print(f\"   speaker: {first_meta.get('speaker', 'NOT FOUND')}\")\n",
    "        \n",
    "        if first_meta.get('test_field') == 'test_value_updated':\n",
    "            print(\"‚úÖ update_by_indexes works correctly!\")\n",
    "        else:\n",
    "            print(\"‚ùå Update verification failed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audio features to test with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caeecb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Quick Actions:\n",
      "\n",
      "# Reset database:\n",
      "!python reset_database.py\n",
      "\n",
      "# Run GMM clustering:\n",
      "!python speaker_gmm/gmm_clustering.py auto\n",
      "!python speaker_gmm/gmm_clustering.py update\n",
      "\n",
      "# Test pipeline:\n",
      "!python main.py\n"
     ]
    }
   ],
   "source": [
    "# Quick Actions and Commands\n",
    "print(\"‚ö° Quick Actions:\")\n",
    "print(\"\\n# Reset database:\")\n",
    "print(\"!python reset_database.py\")\n",
    "\n",
    "print(\"\\n# Run GMM clustering:\")\n",
    "print(\"!python speaker_gmm/gmm_clustering.py auto\")\n",
    "print(\"!python speaker_gmm/gmm_clustering.py update\")\n",
    "\n",
    "print(\"\\n# Test pipeline:\")\n",
    "print(\"!python main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03febb43",
   "metadata": {},
   "source": [
    "# ML Clustering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd766bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ ML CLUSTERING SYSTEM TEST\n",
      "==================================================\n",
      "‚úÖ Initial Clustering State:\n",
      "   Is clustered: False\n",
      "‚úÖ Generated Test Data:\n",
      "   Total samples: 16\n",
      "   Male samples: 8\n",
      "   Female samples: 8\n",
      "   Feature dimensions: 14\n",
      "\n",
      "ÔøΩÔøΩ Testing K-means Clustering...\n",
      "‚úÖ Clustering Successful!\n",
      "   Clusters: 2\n",
      "   Samples: 16\n",
      "   Silhouette score: 0.187\n",
      "   Method: kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpeakerClustering' object has no attribute 'identify_speaker_from_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Test speaker identification\u001b[39;00m\n\u001b[32m     95\u001b[39m test_features = {\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33menergy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1300.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpitch_estimate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m110.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzero_crossings\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m38\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspectral_centroid\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m650.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_variance\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m160.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpeak_amplitude\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2600.0\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrms_energy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1050.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.22\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_3\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.12\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformant_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m420.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mformant_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1250.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjitter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.019\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshimmer\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.026\u001b[39m\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m speaker_name, confidence = \u001b[43mclustering\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_speaker_from_features\u001b[49m(test_features)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Speaker Identification Test:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Identified speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpeakerClustering' object has no attribute 'identify_speaker_from_features'"
     ]
    }
   ],
   "source": [
    "# Test 2: ML Clustering System Verification\n",
    "\n",
    "print(\"üß™ ML CLUSTERING SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test ML clustering system\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "clustering = SpeakerClustering()\n",
    "\n",
    "# Check initial state\n",
    "initial_stats = clustering.get_clustering_stats()\n",
    "print(f\"‚úÖ Initial Clustering State:\")\n",
    "print(f\"   Is clustered: {initial_stats['is_clustered']}\")\n",
    "\n",
    "# Create synthetic training data\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic audio features for testing\n",
    "def generate_synthetic_features(speaker_type=\"male\", num_samples=5):\n",
    "    \"\"\"Generate synthetic audio features for testing\"\"\"\n",
    "    features_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    base_features = {\n",
    "        'male': {\n",
    "            'energy': 1200.0, 'pitch_estimate': 100.0, 'formant_1': 400.0\n",
    "        },\n",
    "        'female': {\n",
    "            'energy': 2000.0, 'pitch_estimate': 180.0, 'formant_1': 600.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base = base_features[speaker_type]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Add some variation\n",
    "        features = {\n",
    "            'energy': base['energy'] + np.random.normal(0, 100),\n",
    "            'pitch_estimate': base['pitch_estimate'] + np.random.normal(0, 10),\n",
    "            'zero_crossings': 35 + np.random.normal(0, 5),\n",
    "            'spectral_centroid': 600 + np.random.normal(0, 50),\n",
    "            'energy_variance': 150 + np.random.normal(0, 20),\n",
    "            'peak_amplitude': 2500 + np.random.normal(0, 200),\n",
    "            'rms_energy': 1000 + np.random.normal(0, 100),\n",
    "            'mfcc_1': 0.3 + np.random.normal(0, 0.05),\n",
    "            'mfcc_2': 0.2 + np.random.normal(0, 0.05),\n",
    "            'mfcc_3': 0.1 + np.random.normal(0, 0.05),\n",
    "            'formant_1': base['formant_1'] + np.random.normal(0, 20),\n",
    "            'formant_2': 1200 + np.random.normal(0, 50),\n",
    "            'jitter': 0.018 + np.random.normal(0, 0.005),\n",
    "            'shimmer': 0.025 + np.random.normal(0, 0.005)\n",
    "        }\n",
    "        \n",
    "        features_list.append(list(features.values()))\n",
    "        metadata_list.append({\n",
    "            'conversation_id': f'test_conv_{speaker_type}_{i}',\n",
    "            'session_id': f'test_session_{speaker_type}',\n",
    "            'speaker': f'{speaker_type.capitalize()}Speaker',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'feature_count': 14\n",
    "        })\n",
    "    \n",
    "    return features_list, metadata_list\n",
    "\n",
    "# Generate test data\n",
    "male_features, male_metadata = generate_synthetic_features(\"male\", 8)\n",
    "female_features, female_metadata = generate_synthetic_features(\"female\", 8)\n",
    "\n",
    "# Combine all features\n",
    "all_features = male_features + female_features\n",
    "all_metadata = male_metadata + female_metadata\n",
    "\n",
    "print(f\"‚úÖ Generated Test Data:\")\n",
    "print(f\"   Total samples: {len(all_features)}\")\n",
    "print(f\"   Male samples: {len(male_features)}\")\n",
    "print(f\"   Female samples: {len(female_features)}\")\n",
    "print(f\"   Feature dimensions: {len(all_features[0])}\")\n",
    "\n",
    "# Test clustering\n",
    "print(f\"\\nÔøΩÔøΩ Testing K-means Clustering...\")\n",
    "result = clustering.perform_clustering(\n",
    "    all_features, all_metadata,\n",
    "    method='kmeans',\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"‚úÖ Clustering Successful!\")\n",
    "    print(f\"   Clusters: {result['n_clusters']}\")\n",
    "    print(f\"   Samples: {result['n_samples']}\")\n",
    "    print(f\"   Silhouette score: {result['silhouette_score']:.3f}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    \n",
    "    # Test speaker identification\n",
    "    test_features = {\n",
    "        'energy': 1300.0, 'pitch_estimate': 110.0, 'zero_crossings': 38,\n",
    "        'spectral_centroid': 650.0, 'energy_variance': 160.0, 'peak_amplitude': 2600.0,\n",
    "        'rms_energy': 1050.0, 'mfcc_1': 0.32, 'mfcc_2': 0.22, 'mfcc_3': 0.12,\n",
    "        'formant_1': 420.0, 'formant_2': 1250.0, 'jitter': 0.019, 'shimmer': 0.026\n",
    "    }\n",
    "    \n",
    "    speaker_name, confidence = clustering.identify_speaker_from_features(test_features)\n",
    "    print(f\"‚úÖ Speaker Identification Test:\")\n",
    "    print(f\"   Identified speaker: {speaker_name}\")\n",
    "    print(f\"   Confidence: {confidence:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Clustering failed: {result.get('reason', 'unknown')}\")\n",
    "\n",
    "print(\"üéâ ML clustering system is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration test\n",
    "\n",
    "# Test 3: Database + ML Integration Test\n",
    "print(\"üß™ INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the complete pipeline\n",
    "from speech.speech_processor import SpeakerDetector\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "\n",
    "# Initialize components\n",
    "db = EnhancedConversationDB()\n",
    "clustering = SpeakerClustering()\n",
    "speaker_detector = SpeakerDetector(\n",
    "    enhanced_db=db,\n",
    "    speaker_clustering=clustering\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Components Initialized:\")\n",
    "print(f\"   Database: {type(db).__name__}\")\n",
    "print(f\"   Clustering: {type(clustering).__name__}\")\n",
    "print(f\"   Speaker Detector: {type(speaker_detector).__name__}\")\n",
    "\n",
    "# Test speaker detection with ML\n",
    "import numpy as np\n",
    "\n",
    "# Simulate audio processing\n",
    "dummy_audio = np.random.randint(-1000, 1000, size=2048, dtype=np.int16).tobytes()\n",
    "\n",
    "print(f\"\\nüîß Testing Speaker Detection with ML:\")\n",
    "print(f\"   Initial speaker: {speaker_detector.current_speaker}\")\n",
    "\n",
    "# Process multiple audio frames to build up features\n",
    "for i in range(10):\n",
    "    speaker_detector.update_speaker_count(dummy_audio, 0)\n",
    "\n",
    "print(f\"   After processing: {speaker_detector.current_speaker}\")\n",
    "print(f\"   Speaker changes: {speaker_detector.speaker_changes}\")\n",
    "print(f\"   Feature buffer size: {len(speaker_detector.feature_buffer)}\")\n",
    "\n",
    "# Test feature extraction\n",
    "current_features = speaker_detector.get_current_features()\n",
    "print(f\"   Current features available: {current_features is not None}\")\n",
    "if current_features:\n",
    "    print(f\"   Feature count: {len(current_features)}\")\n",
    "\n",
    "# Test database integration\n",
    "if current_features:\n",
    "    # Add to database\n",
    "    db.add_conversation_with_audio(\n",
    "        session_id=\"integration_test\",\n",
    "        text=\"Integration test conversation\",\n",
    "        speaker=speaker_detector.current_speaker,\n",
    "        role=\"user\",\n",
    "        is_gemma_mode=False,\n",
    "        audio_features=current_features\n",
    "    )\n",
    "    \n",
    "    # Verify storage\n",
    "    stats = db.get_conversation_stats()\n",
    "    print(f\"‚úÖ Database Integration:\")\n",
    "    print(f\"   Total conversations: {stats['total_conversations']}\")\n",
    "    print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "\n",
    "print(\"üéâ Integration test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee07c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline test\n",
    "\n",
    "# Test 4: Training Pipeline Test\n",
    "print(\"üß™ TRAINING PIPELINE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the training script functionality\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the tests directory to path\n",
    "sys.path.append('tests')\n",
    "\n",
    "# Import the training function\n",
    "from train_unsupervised_speakers_new import train_unsupervised_speakers, analyze_clustering_quality\n",
    "\n",
    "print(\"‚úÖ Training functions imported successfully\")\n",
    "\n",
    "# Check if we have enough data for training\n",
    "stats = db.get_conversation_stats()\n",
    "print(f\"üìä Current Data Status:\")\n",
    "print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "print(f\"   Need for training: 10+\")\n",
    "\n",
    "if stats['total_audio_features'] >= 10:\n",
    "    print(\"‚úÖ Sufficient data for training!\")\n",
    "    print(\"   Run: train_unsupervised_speakers() to train clustering\")\n",
    "else:\n",
    "    print(\"‚è≥ Need more data for training\")\n",
    "    print(\"   Continue using the system to collect more audio features\")\n",
    "\n",
    "# Test analysis function\n",
    "print(f\"\\nüîç Testing Analysis Function:\")\n",
    "try:\n",
    "    analyze_clustering_quality()\n",
    "    print(\"‚úÖ Analysis function works!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Analysis function error: {e}\")\n",
    "\n",
    "print(\"üéâ Training pipeline test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5a272",
   "metadata": {},
   "source": [
    "# Delete database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ba66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Old database deleted - ready for 14-feature data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"‚úÖ Old database deleted - ready for 14-feature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f399dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database cleared for fresh start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedConversationDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Database cleared for fresh start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create completely fresh database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m db = \u001b[43mEnhancedConversationDB\u001b[49m()\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Fresh database ready\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EnhancedConversationDB' is not defined"
     ]
    }
   ],
   "source": [
    "# Final database clear\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"‚úÖ Database cleared for fresh start\")\n",
    "\n",
    "# Create completely fresh database\n",
    "db = EnhancedConversationDB()\n",
    "print(\"‚úÖ Fresh database ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
