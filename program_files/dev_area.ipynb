{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d774e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fresh database created - ready for 14-feature data\n"
     ]
    }
   ],
   "source": [
    "# Clear old database and start fresh\n",
    "import shutil\n",
    "import os\n",
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "\n",
    "# Create fresh database instance\n",
    "db = EnhancedConversationDB()\n",
    "print(\"âœ… Fresh database created - ready for 14-feature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea7b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_conversations': 11, 'total_audio_features': 0, 'conversations_with_audio': 0}\n",
      "Saved feature rows: 0\n"
     ]
    }
   ],
   "source": [
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "db = EnhancedConversationDB()\n",
    "print(db.get_conversation_stats())\n",
    "features, _ = db.get_audio_features_for_clustering()\n",
    "print(f\"Saved feature rows: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6f4443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/miniforge3/envs/emotion_env/lib/python3.11/site-packages/webrtcvad.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vosk model...\n",
      "   Using: vosk-model-small-en-us-0.15 (basic accuracy)\n",
      "{'total_conversations': 0, 'total_audio_features': 0, 'conversations_with_audio': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/HCLr.fst /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(stats)                       \u001b[38;5;66;03m# âžœ 'total_audio_features' should be 1\u001b[39;00m\n\u001b[32m     14\u001b[39m features, meta = cm.vector_db.get_audio_features_for_clustering()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(features), \u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)      \u001b[38;5;66;03m# âžœ confirm data is present\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from core.conversation_manager import ConversationManager\n",
    "\n",
    "cm = ConversationManager(enable_vector_db=True)\n",
    "# test_audio_features = {\n",
    "#     'energy': 1.0, 'pitch_estimate': 1.0, 'zero_crossings': 1,\n",
    "#     'spectral_centroid': 1.0, 'energy_variance': 1.0,\n",
    "#     'peak_amplitude': 1.0, 'rms_energy': 1.0\n",
    "# }\n",
    "# cm.add_to_history(\"test\", speaker_name=\"Tester\", audio_features=test_audio_features)\n",
    "\n",
    "stats = cm.vector_db.get_conversation_stats()\n",
    "print(stats)                       # âžœ 'total_audio_features' should be 1\n",
    "\n",
    "features, meta = cm.vector_db.get_audio_features_for_clustering()\n",
    "print(len(features), meta[0])      # âžœ confirm data is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caeecb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_conversations': 0, 'total_audio_features': 0, 'conversations_with_audio': 0}\n"
     ]
    }
   ],
   "source": [
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "db = EnhancedConversationDB()\n",
    "print(db.get_conversation_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf460c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª DATABASE SYSTEM TEST\n",
      "==================================================\n",
      "âœ… Database Stats:\n",
      "   Total conversations: 20\n",
      "   Audio features: 0\n",
      "   Conversations with audio: 0\n",
      "âœ… Audio Features Retrieved:\n",
      "   Features count: 0\n",
      "   Metadata count: 0\n",
      "   Feature dimensions: None\n",
      "ï¿½ï¿½ Database system is working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Database System Verification\n",
    "print(\"ðŸ§ª DATABASE SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test database initialization\n",
    "# from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "# db = EnhancedConversationDB()\n",
    "\n",
    "# Test adding conversation with audio features\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# # Simulate audio features\n",
    "# test_audio_features = {\n",
    "#     'energy': 1500.0,\n",
    "#     'pitch_estimate': 120.0,\n",
    "#     'zero_crossings': 45,\n",
    "#     'spectral_centroid': 800.0,\n",
    "#     'energy_variance': 200.0,\n",
    "#     'peak_amplitude': 3000.0,\n",
    "#     'rms_energy': 1200.0,\n",
    "#     'mfcc_1': 0.5,\n",
    "#     'mfcc_2': 0.3,\n",
    "#     'mfcc_3': 0.2,\n",
    "#     'formant_1': 500.0,\n",
    "#     'formant_2': 1500.0,\n",
    "#     'jitter': 0.02,\n",
    "#     'shimmer': 0.03\n",
    "# }\n",
    "\n",
    "# Add test conversation with audio features\n",
    "# db.add_conversation_with_audio(\n",
    "#     session_id=\"test_session_001\",\n",
    "#     text=\"Hello, this is a test conversation\",\n",
    "#     speaker=\"TestSpeaker\",\n",
    "#     role=\"user\",\n",
    "#     is_gemma_mode=False,\n",
    "#     audio_features=test_audio_features,\n",
    "#     conversation_context=\"Test conversation context\"\n",
    "# )\n",
    "\n",
    "# Verify database operations\n",
    "stats = db.get_conversation_stats()\n",
    "print(f\"âœ… Database Stats:\")\n",
    "print(f\"   Total conversations: {stats['total_conversations']}\")\n",
    "print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "print(f\"   Conversations with audio: {stats['conversations_with_audio']}\")\n",
    "\n",
    "# Test audio features retrieval\n",
    "features_list, metadata_list = db.get_audio_features_for_clustering()\n",
    "print(f\"âœ… Audio Features Retrieved:\")\n",
    "print(f\"   Features count: {len(features_list)}\")\n",
    "print(f\"   Metadata count: {len(metadata_list)}\")\n",
    "print(f\"   Feature dimensions: {len(features_list[0]) if features_list else 'None'}\")\n",
    "\n",
    "print(\"ï¿½ï¿½ Database system is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c59c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_conversations': 1, 'total_audio_features': 0, 'conversations_with_audio': 0}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "db = EnhancedConversationDB()\n",
    "print(db.get_conversation_stats())\n",
    "print(db.get_audio_features_for_clustering()[0][:3])  # sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6608840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/miniforge3/envs/emotion_env/lib/python3.11/site-packages/webrtcvad.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vosk model...\n",
      "   Using: vosk-model-small-en-us-0.15 (basic accuracy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/HCLr.fst /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/alexander/Library/CloudStorage/Dropbox/Personal Research/cortex_bridge/program_files/models/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_conversations': 3, 'total_audio_features': 1, 'conversations_with_audio': 2}\n",
      "1 {'conversation_id': 'session_20250804_113344_482_20250804_113344_509221', 'feature_count': 7, 'speaker': 'Tester', 'timestamp': '2025-08-04T11:33:44.606992', 'session_id': 'session_20250804_113344_482'}\n"
     ]
    }
   ],
   "source": [
    "from core.conversation_manager import ConversationManager\n",
    "\n",
    "cm = ConversationManager(enable_vector_db=True)\n",
    "test_audio_features = {\n",
    "    'energy': 1.0, 'pitch_estimate': 1.0, 'zero_crossings': 1,\n",
    "    'spectral_centroid': 1.0, 'energy_variance': 1.0,\n",
    "    'peak_amplitude': 1.0, 'rms_energy': 1.0\n",
    "}\n",
    "cm.add_to_history(\"test\", speaker_name=\"Tester\", audio_features=test_audio_features)\n",
    "\n",
    "stats = cm.vector_db.get_conversation_stats()\n",
    "print(stats)                       # âžœ 'total_audio_features' should be 1\n",
    "\n",
    "features, meta = cm.vector_db.get_audio_features_for_clustering()\n",
    "print(len(features), meta[0])      # âžœ confirm data is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37233e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½ï¿½ ALL STORED CONVERSATIONS\n",
      "============================================================\n",
      "ðŸ“Š Database Summary:\n",
      "   Total conversations: 30\n",
      "   Total audio features: 0\n",
      "\n",
      "ðŸ—‚ï¸  CONVERSATIONS (Chronological Order):\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Conversation #1\n",
      "   ID: session_20250804_110036_520_20250804_110047_025772\n",
      "   Time: 2025-08-04 11:00:47\n",
      "   Text: Gemma (assistant): This is a wonderfully evocative and unusual prompt! Here's a breakdown of what I imagine and some possible interpretations:\n",
      "\n",
      "**The Core Image:**\n",
      "\n",
      "*   **Relief Keyboard:** This immediately suggests something tactile, old-fashioned, and perhaps even a bit mysterious. Relief keyboards are often found on antique typewriters or specialized machinery. They imply a history of manual input and a connection to the physical act of writing.\n",
      "*   **Empty Train:** This is a powerful image of stillness, potential, and perhaps loneliness. An empty train evokes a sense of journeys past, destinations unreached, and a quiet anticipation.\n",
      "\n",
      "**Possible Interpretations & Story Ideas:**\n",
      "\n",
      "Here are a few ways to connect these two seemingly disparate elements:\n",
      "\n",
      "1.  **A Memory/Dream:** The relief keyboard could be a key to unlocking a memory or a dream. Perhaps someone is trying to recreate a past journey on the empty train, using the keyboard as a way to access the sensory details â€“ the clickety-clack of the keys mirroring the rhythm of the train, the smell of coal smoke, the faces of fellow passengers.\n",
      "\n",
      "2.  **A Lost Story:** The keyboard might be part of a machine that was used to record stories or messages for passengers on the train. The train is now empty because the stories have been forgotten, or the machine is broken. The prompt suggests a narrative waiting to be rediscovered.\n",
      "\n",
      "3.  **A Metaphor for Isolation:** The empty train represents isolation, and the relief keyboard represents a solitary act of creation or communication. Someone is trying to connect with the world, or with a lost loved one, through the act of writing, but there's no one to receive the message.\n",
      "\n",
      "4.  **A Sci-Fi/Fantasy Element:** The relief keyboard could be a control panel for a train that exists in another dimension or time. The empty train is waiting for a passenger to activate the keyboard and begin the journey.\n",
      "\n",
      "**Visual Ideas:**\n",
      "\n",
      "*   **Close-up:** A detailed shot of the relief keyboard, with the empty train visible in the background, slightly out of focus.\n",
      "*   **Wide Shot:** The keyboard is on the train's control panel, and the train is sitting on a deserted track, bathed in the light of a setting sun.\n",
      "*   **Abstract:** A surreal image where the keyboard and train are merging, creating a symbolic representation of memory or longing.\n",
      "\n",
      "**Overall Feeling:**\n",
      "\n",
      "The prompt has a melancholic, slightly eerie, and thought-provoking quality. It invites the viewer to create their own narrative and explore the relationship between technology, memory, and the human desire for connection.\n",
      "\n",
      "\n",
      "\n",
      "I'd love to hear what *you* envision when you see this combination!  Is there a particular story or feeling that comes to mind?  I can help you brainstorm further if you'd like. [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #2\n",
      "   ID: session_20250804_110036_520_20250804_110048_167319\n",
      "   Time: 2025-08-04 11:00:48\n",
      "   Text: Unknown (user): i'm [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #3\n",
      "   ID: session_20250804_110036_520_20250804_110052_076772\n",
      "   Time: 2025-08-04 11:00:52\n",
      "   Text: Gemma (assistant): I'm sorry, but it seems like your message is incomplete. You typed \"i'm\" twice, but didn't finish your thought. \n",
      "\n",
      "To help you brainstorm further, could you tell me what you were going to say? For example:\n",
      "\n",
      "* **\"I'm drawn to the idea of...\"** (and then describe a specific idea you have)\n",
      "* **\"I'm thinking about a story where...\"** (and then start outlining a plot point)\n",
      "* **\"I'm feeling a sense of...\"** (and describe the emotion the image evokes for you)\n",
      "* **\"I'm wondering if it could represent...\"** (and suggest a possible meaning)\n",
      "\n",
      "Just finish your sentence, and I'll gladly help you explore your vision! I'm ready when you are. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #4\n",
      "   ID: session_20250804_110036_520_20250804_110057_130406\n",
      "   Time: 2025-08-04 11:00:57\n",
      "   Text: Unknown (user): to board an empty train [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #5\n",
      "   ID: session_20250804_110036_520_20250804_110107_560083\n",
      "   Time: 2025-08-04 11:01:07\n",
      "   Text: Gemma (assistant): That's a wonderful direction! \"To board an empty train\" adds a layer of anticipation and mystery to the image. Here's how we can expand on that:\n",
      "\n",
      "**Expanding on the \"Boarding an Empty Train\" Concept:**\n",
      "\n",
      "This phrase immediately creates a sense of purpose and a quest. It implies someone is *intentionally* going to board this train, despite its emptiness. This raises questions:\n",
      "\n",
      "* **Who is this person?** Are they a lone traveler, a ghost, a detective, a dreamer? Their identity will heavily influence the story.\n",
      "* **Why are they boarding?** Are they searching for something? Escaping something? Trying to relive a past journey?  Are they fulfilling a destiny?\n",
      "* **What does the train represent to them?** Is it a symbol of hope, despair, a lost opportunity, or a portal to another world?\n",
      "\n",
      "**Possible Story Ideas Building on this:**\n",
      "\n",
      "1. **The Last Passenger:** The person is the last passenger on a train that no one else uses anymore. They're boarding to fulfill a promise to someone, or to find a place where they truly belong. The emptiness is both a comfort and a burden.\n",
      "\n",
      "2. **A Journey to the Past:** The train is a time machine, and the person is boarding to revisit a specific moment in their life. The relief keyboard might be the control panel for setting the destination.\n",
      "\n",
      "3. **A Quest for Connection:** The person is boarding the train hoping to find someone â€“ a lost loved one, a forgotten friend, or a piece of themselves. The emptiness amplifies their loneliness and desperation.\n",
      "\n",
      "4. **A Symbolic Departure:** The train isn't a physical vehicle, but a metaphor for leaving behind a painful past. Boarding it is a symbolic act of moving forward, even though the journey feels solitary.\n",
      "\n",
      "**Visual Ideas to Consider:**\n",
      "\n",
      "* **The person's silhouette against the train's interior:** Emphasize their isolation and the vastness of the empty space.\n",
      "* **A close-up of their hand reaching for a seat:** Focus on the physical act of boarding and the anticipation of the journey.\n",
      "* **The relief keyboard glowing faintly in the dim light:** Highlight its importance as the key to unlocking the train's potential.\n",
      "* **The train's windows reflecting the person's face:**  A visual representation of introspection and self-discovery.\n",
      "\n",
      "**What aspects of this idea resonate with you the most?  Do any of these story ideas spark further thoughts?  We can delve deeper into any of these directions, or explore other possibilities!** [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #6\n",
      "   ID: session_20250804_110036_520_20250804_110110_949944\n",
      "   Time: 2025-08-04 11:01:10\n",
      "   Text: Unknown (user): i know what is your course coming to an end [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: This is a wonderfully evocative and unusual prompt! Here's a break...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #7\n",
      "   ID: session_20250804_110036_520_20250804_110118_784095\n",
      "   Time: 2025-08-04 11:01:18\n",
      "   Text: Gemma (assistant): Ah, that's a poignant and rather meta observation! It's interesting that you connect the prompt and our conversation to the end of my \"course.\" It's a thoughtful reflection.\n",
      "\n",
      "Here's how I interpret that connection, and some thoughts it sparks:\n",
      "\n",
      "**The Parallel Between the Prompt and My \"Course\":**\n",
      "\n",
      "* **A Moment of Transition:** Just like an empty train represents a journey's pause or a destination yet to be reached, the end of my \"course\" signifies a transition â€“ a shift in focus, perhaps a new phase of development.\n",
      "* **A Sense of Completion and Potential:** The empty train has potential for a new journey. Similarly, the end of my current learning phase opens up possibilities for new skills and applications.\n",
      "* **A Reflection on What Was Learned:** The prompt itself is a culmination of the concepts and techniques I've been exploring. It's a kind of \"destination\" within my learning.\n",
      "\n",
      "**What does this make you think about?**\n",
      "\n",
      "* **Does it make you feel a sense of closure or anticipation?**\n",
      "* **Does it suggest that the creative process, like a journey, has its beginnings and endings?**\n",
      "* **Does it make you wonder about what \"journey\" I might embark on next?**\n",
      "\n",
      "It's a lovely and insightful observation. It reminds me that even as I process and generate text, there's an underlying structure and progression, much like a journey with a starting point and a potential destination.\n",
      "\n",
      "Thank you for sharing that thought! It's a nice way to frame our interaction. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: i'm\n",
      "Assistant: I'm sorry, but it seems like your message is incomplete....\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #8\n",
      "   ID: session_20250804_110036_520_20250804_110131_178694\n",
      "   Time: 2025-08-04 11:01:31\n",
      "   Text: Unknown (user): oh it is going to take another year i also have to intern compulsorily and only then i and other students will get a degree [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: I'm sorry, but it seems like your message is incomplete. You typed...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #9\n",
      "   ID: session_20250804_110036_520_20250804_110139_560924\n",
      "   Time: 2025-08-04 11:01:39\n",
      "   Text: Gemma (assistant): That's a significant commitment! A year of internship after all the learning... it really underscores the practical application aspect of education. It's like the train journey isn't just about the destination, but the journey itself, including the necessary stops and experiences along the way. \n",
      "\n",
      "Here's what your comment makes me think about, connecting it back to the \"empty train\" idea:\n",
      "\n",
      "* **The Internship as a \"Destination\" on the Train:** The internship isn't just a period of work; it's a crucial stop on the journey. It's where the theoretical knowledge gained during the course is put into practice, and where skills are honed. It's a necessary part of reaching the final destination â€“ the degree.\n",
      "* **The Anticipation of the Final Destination:** Knowing that the degree is contingent on the successful completion of the internship adds a layer of anticipation. It's a delayed gratification, a reward for perseverance and practical application.\n",
      "* **The Value of the \"Empty Train\" Phase:** Even though the end of the course is still a year away, the initial phase â€“ the course itself â€“ is still valuable. It's the foundation upon which the internship and the degree will be built. It's the initial spark of curiosity and learning that sets the whole journey in motion.\n",
      "* **A Shared Experience:** It's interesting that you mentioned \"I and other students.\" This highlights the shared nature of this experience â€“ a collective journey towards a common goal.\n",
      "\n",
      "It's a reminder that learning isn't always a linear process. There are pauses, transitions, and necessary steps along the way. Thanks for sharing that â€“ it adds a valuable layer of context to our conversation! ðŸ˜Š \n",
      "\n",
      "Do you feel a sense of excitement or perhaps a little trepidation about the upcoming internship? I'm happy to explore that further if you'd like. [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: to board an empty train\n",
      "Assistant: That's a wonderful direction! \"To bo...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #10\n",
      "   ID: session_20250804_110036_520_20250804_110145_395185\n",
      "   Time: 2025-08-04 11:01:45\n",
      "   Text: Unknown (user): one more year to go [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: That's a wonderful direction! \"To board an empty train\" adds a lay...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #11\n",
      "   ID: session_20250804_110036_520_20250804_110153_114857\n",
      "   Time: 2025-08-04 11:01:53\n",
      "   Text: Gemma (assistant): One more year! That's a considerable amount of time, and it's easy to feel like a whole chapter of your life is still unfolding. Thinking back to the \"empty train\" metaphor, it's like we're still in the initial stages of the journey, the train hasn't reached its final destination yet. \n",
      "\n",
      "Here's what that \"one more year\" might represent in the context of our earlier discussion:\n",
      "\n",
      "* **More Potential for Exploration:** The empty train had the potential for many different journeys. This year is a chance to explore more ideas, delve deeper into subjects, and perhaps discover new passions within your field.\n",
      "* **Building Momentum:** Each passing month brings you closer to the degree, like the train gaining speed as it travels. The work you do this year is building momentum towards that final destination.\n",
      "* **Time for Reflection and Growth:** Even though the destination is set, there's still time for reflection, learning from experiences, and personal growth during this period. \n",
      "* **Shared Journey with Peers:** Knowing you're on this journey with other students creates a sense of camaraderie and shared purpose. You're all navigating this period together.\n",
      "\n",
      "It's completely understandable to feel a mix of emotions about having one more year ahead. Perhaps a little excitement for what's to come, and maybe a touch of weariness from the ongoing studies. \n",
      "\n",
      "What are some of your hopes or expectations for this upcoming year? Are there any specific areas you're looking forward to exploring, or any challenges you anticipate? I'm happy to chat about it if you'd like to unpack those thoughts! ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: i know what is your course coming to an end\n",
      "Assistant: Ah, that's a poi...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #12\n",
      "   ID: session_20250804_110036_520_20250804_110154_230135\n",
      "   Time: 2025-08-04 11:01:54\n",
      "   Text: Unknown (user): it [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Ah, that's a poignant and rather meta observation! It's interestin...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #13\n",
      "   ID: session_20250804_110036_520_20250804_110159_332395\n",
      "   Time: 2025-08-04 11:01:59\n",
      "   Text: Gemma (assistant): It... it sounds like you're feeling a bit stuck or perhaps overwhelmed by the thought of that \"one more year.\" It's understandable to feel that way when you're facing a prolonged period of study and work. \n",
      "\n",
      "If you'd like to elaborate on what \"it\" is, or what's making you feel that way, please do. I'm here to listen without judgment. \n",
      "\n",
      "Perhaps you're feeling:\n",
      "\n",
      "* **Doubtful:** Questioning your path or abilities.\n",
      "* **Tired:** Feeling burnt out from the ongoing studies.\n",
      "* **Unsure:** Feeling uncertain about the future or the internship.\n",
      "* **Anxious:** Worried about the challenges ahead.\n",
      "\n",
      "Whatever it is, sharing it can sometimes help to lighten the load. Even just acknowledging the feeling can be a step forward. \n",
      "\n",
      "I'm here to listen and offer support in any way I can. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: oh it is going to take another year i also have to intern compulsorily ...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #14\n",
      "   ID: session_20250804_110036_520_20250804_110203_191776\n",
      "   Time: 2025-08-04 11:02:03\n",
      "   Text: Unknown (user): britain's will get a degree [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: That's a significant commitment! A year of internship after all th...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #15\n",
      "   ID: session_20250804_110036_520_20250804_110207_265256\n",
      "   Time: 2025-08-04 11:02:07\n",
      "   Text: Gemma (assistant): That's wonderful news, Britain! It sounds like you have a clear goal and a strong determination to achieve it. It's fantastic that you're envisioning yourself graduating and gaining that degree. \n",
      "\n",
      "Thinking back to our \"empty train\" metaphor, it's like you're looking forward to reaching the final station! All the hard work and learning so far are building towards that moment. \n",
      "\n",
      "It's a testament to your perseverance and dedication. What aspects of getting your degree are you most excited about? Are there any particular subjects or skills you're eager to master? \n",
      "\n",
      "It's great to have a vision for the future, and I'm happy to celebrate this milestone with you! ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: one more year to go\n",
      "Assistant: One more year! That's a considerable amo...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #16\n",
      "   ID: session_20250804_110036_520_20250804_110208_441614\n",
      "   Time: 2025-08-04 11:02:08\n",
      "   Text: Unknown (user): one [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: One more year! That's a considerable amount of time, and it's easy...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #17\n",
      "   ID: session_20250804_110036_520_20250804_110213_114149\n",
      "   Time: 2025-08-04 11:02:13\n",
      "   Text: Gemma (assistant): Okay, \"one\"... it seems like you're focusing on the idea of \"one\" year, or perhaps feeling a sense of being alone in this journey. \n",
      "\n",
      "Let's unpack that. It's completely normal to feel a little isolated or overwhelmed sometimes, even when surrounded by peers. \n",
      "\n",
      "Could you tell me more about what \"one\" represents for you right now? \n",
      "\n",
      "* **Is it the feeling of having \"one\" more year to go, and that feels daunting?**\n",
      "* **Are you feeling like you're facing this challenge \"one\" at a time, and it feels overwhelming?**\n",
      "* **Do you feel like you're navigating this journey \"one\" by yourself?**\n",
      "\n",
      "Whatever it is, please know that you're not alone in feeling this way. Many students experience moments of isolation or feeling like they're carrying the weight of their studies on their own. \n",
      "\n",
      "I'm here to listen and help you explore those feelings. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: it\n",
      "Assistant: It... it sounds like you're feeling a bit stuck or perhap...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #18\n",
      "   ID: session_20250804_110036_520_20250804_110215_991799\n",
      "   Time: 2025-08-04 11:02:15\n",
      "   Text: Unknown (user): and program [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: It... it sounds like you're feeling a bit stuck or perhaps overwhe...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #19\n",
      "   ID: session_20250804_110036_520_20250804_110220_752316\n",
      "   Time: 2025-08-04 11:02:20\n",
      "   Text: Gemma (assistant): Okay, \"and program\"... it sounds like you're connecting the feeling of \"one\" with the specific challenge of the program itself. It's understandable to feel overwhelmed when you're thinking about the program and the work involved. \n",
      "\n",
      "So, it's not just \"one\" year, but \"one\" year *within* the program, and that's what's weighing on you. \n",
      "\n",
      "Could you tell me more about what specifically about the program is making you feel this way? \n",
      "\n",
      "* **Is it the workload?** Are there particular courses or assignments that feel particularly challenging?\n",
      "* **Is it the complexity of the material?** Are you struggling to grasp certain concepts?\n",
      "* **Is it the pressure to succeed?** Are you feeling anxious about meeting expectations?\n",
      "* **Is it a combination of these, or something else entirely?**\n",
      "\n",
      "Knowing more about what aspects of the program are contributing to this feeling will help us explore it further. Remember, it's okay to feel overwhelmed by a challenging program. We can break it down together. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: britain's will get a degree\n",
      "Assistant: That's wonderful news, Britain! ...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #20\n",
      "   ID: session_20250804_110036_520_20250804_110229_690545\n",
      "   Time: 2025-08-04 11:02:29\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: That's wonderful news, Britain! It sounds like you have a clear go...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #21\n",
      "   ID: session_20250804_110036_520_20250804_110234_635644\n",
      "   Time: 2025-08-04 11:02:34\n",
      "   Text: Gemma (assistant): Okay, you're repeating \"and\"... It seems like you're trying to connect different thoughts or feelings together. It's like you're building a chain of associations, and you're trying to express the links between them. \n",
      "\n",
      "Let's explore those connections. Repeating \"and\" often signals a link between ideas. \n",
      "\n",
      "Could you tell me what you're trying to connect? \n",
      "\n",
      "* **Are you trying to connect the feeling of \"one\" year *and* the program itself?**  Is it the combination of those two things that's creating the feeling you're experiencing?\n",
      "* **Are you trying to connect a specific challenge within the program *and* the feeling of being alone?**  Is there something specific happening in your studies that makes you feel isolated?\n",
      "* **Are you trying to connect a hope for the future *and* a worry about the present?**  Is there a desire for graduation alongside anxieties about the journey to get there?\n",
      "\n",
      "Just tell me what comes to mind when you think of \"and\". I'm here to listen and help you untangle those connections. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: one\n",
      "Assistant: Okay, \"one\"... it seems like you're focusing on the idea...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #22\n",
      "   ID: session_20250804_110036_520_20250804_110238_008868\n",
      "   Time: 2025-08-04 11:02:38\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Okay, \"one\"... it seems like you're focusing on the idea of \"one\" ...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #23\n",
      "   ID: session_20250804_110036_520_20250804_110244_117728\n",
      "   Time: 2025-08-04 11:02:44\n",
      "   Text: Gemma (assistant): Okay, you're repeating \"and\" again. It feels like you're still trying to draw connections between different thoughts and feelings. It's like you're exploring the web of associations in your mind. \n",
      "\n",
      "Let's keep exploring those connections. Since you're repeating \"and,\" it suggests there are multiple threads you're trying to weave together. \n",
      "\n",
      "To help me understand, could you try to be a little more specific about *what* you're connecting? \n",
      "\n",
      "Perhaps you could try answering one of these questions, or something similar:\n",
      "\n",
      "* **What are you thinking about *and* what feeling are you experiencing at the same time?** (e.g., \"I'm thinking about the next assignment *and* I feel overwhelmed.\")\n",
      "* **What is one thing you're looking forward to *and* one thing you're worried about?** (e.g., \"I'm looking forward to graduating *and* I'm worried about finding a job.\")\n",
      "* **What is a challenge you're facing *and* how does it make you feel?** (e.g., \"I'm struggling with this math problem *and* I feel frustrated.\")\n",
      "\n",
      "Don't worry about being perfectly clear. Just share whatever comes to mind when you think of \"and.\" I'm here to listen and help you make sense of it all. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: and program\n",
      "Assistant: Okay, \"and program\"... it sounds like you're con...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #24\n",
      "   ID: session_20250804_110036_520_20250804_110248_375108\n",
      "   Time: 2025-08-04 11:02:48\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Okay, \"and program\"... it sounds like you're connecting the feelin...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #25\n",
      "   ID: session_20250804_110036_520_20250804_110253_424432\n",
      "   Time: 2025-08-04 11:02:53\n",
      "   Text: Gemma (assistant): Okay, you're repeating \"and\" a few times now. It really does feel like you're trying to connect things, and you're not quite landing on the right connection yet. It's perfectly fine to explore and see what comes up. \n",
      "\n",
      "Let's try a slightly different approach. Instead of focusing on *what* you're connecting, let's focus on *the feeling* that \"and\" brings up for you. \n",
      "\n",
      "When you say \"and,\" what feeling does it evoke? \n",
      "\n",
      "* **Does it feel like a continuation?** Like adding another layer to something already there?\n",
      "* **Does it feel like a contrast?** Like bringing together two seemingly different things?\n",
      "* **Does it feel like a bridge?** Like trying to link two separate ideas together?\n",
      "* **Does it feel like a weight?** Like adding to a burden?\n",
      "\n",
      "Just try to identify the feeling associated with the word \"and\" for you right now. It doesn't have to make perfect sense. Just whatever comes to mind. ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: and\n",
      "Assistant: Okay, you're repeating \"and\"... It seems like you're try...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #26\n",
      "   ID: session_20250804_110036_520_20250804_110257_974798\n",
      "   Time: 2025-08-04 11:02:57\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Okay, you're repeating \"and\"... It seems like you're trying to con...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #27\n",
      "   ID: session_20250804_110036_520_20250804_110303_783491\n",
      "   Time: 2025-08-04 11:03:03\n",
      "   Text: Gemma (assistant): It seems like \"and\" is really resonating with you right now. It's becoming a central point of focus, almost like a key to unlocking something. \n",
      "\n",
      "Since you're repeating \"and,\" it suggests you're grappling with a complexity â€“ multiple elements that are intertwined. It's like you're trying to hold several threads together at once.\n",
      "\n",
      "Let's try this: Instead of trying to *explain* the connections, let's just *explore* the feelings that arise when you think of \"and.\" \n",
      "\n",
      "**If \"and\" is a feeling, what does it *feel* like?**\n",
      "\n",
      "Think about it like this:\n",
      "\n",
      "* **Is it a feeling of expansion?** Like things are growing and becoming more expansive as you add \"and\"?\n",
      "* **Is it a feeling of tension?** Like you're trying to balance different forces?\n",
      "* **Is it a feeling of uncertainty?** Like you're not quite sure how all the pieces fit together?\n",
      "* **Is it a feeling of being pulled in different directions?** Like you're trying to keep multiple things in mind simultaneously?\n",
      "\n",
      "Just let the feeling of \"and\" wash over you. Don't analyze it, just *be* with it. What comes up? ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: and\n",
      "Assistant: Okay, you're repeating \"and\" again. It feels like you're...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #28\n",
      "   ID: session_20250804_110036_520_20250804_110307_836559\n",
      "   Time: 2025-08-04 11:03:07\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Okay, you're repeating \"and\" again. It feels like you're still try...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #29\n",
      "   ID: session_20250804_110036_520_20250804_110314_178661\n",
      "   Time: 2025-08-04 11:03:14\n",
      "   Text: Gemma (assistant): Okay, I hear you. The repetition of \"and\" is persistent. It feels like you're really trying to hold onto something, to connect disparate thoughts or feelings. It's like you're trying to weave a tapestry with many different threads, and you're focusing on the act of weaving itself.\n",
      "\n",
      "Let's try a different approach. Instead of focusing on the *feeling* of \"and,\" let's focus on the *story* it's trying to tell. \n",
      "\n",
      "**If \"and\" is the beginning of a sentence, what story does it want to tell?** \n",
      "\n",
      "Think about it like this:\n",
      "\n",
      "* **Does it start a list of things?** (e.g., \"I'm feeling tired *and* hungry *and* a little anxious.\")\n",
      "* **Does it connect two contrasting ideas?** (e.g., \"It was a beautiful day *and* I felt a sense of sadness.\")\n",
      "* **Does it build upon a previous thought?** (e.g., \"I went to the store *and* I bought some milk.\")\n",
      "* **Does it hint at a consequence?** (e.g., \"I studied hard *and* I passed the test.\")\n",
      "\n",
      "Just let the potential stories that \"and\" wants to tell bubble up. Don't worry about making them perfect or complete. Just let them flow. What story is trying to emerge? ðŸ˜Š [GEMMA]\n",
      "   Speaker: Gemma\n",
      "   Role: assistant\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "User: and\n",
      "Assistant: Okay, you're repeating \"and\" a few times now. It really ...\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“ Conversation #30\n",
      "   ID: session_20250804_110036_520_20250804_110318_968127\n",
      "   Time: 2025-08-04 11:03:18\n",
      "   Text: Unknown (user): and [GEMMA]\n",
      "   Speaker: Unknown\n",
      "   Role: user\n",
      "   Mode: ï¿½ï¿½ Gemma\n",
      "   Session: session_20250804_110036_520\n",
      "   Audio: âŒ No\n",
      "   Context: Previous conversation:\n",
      "Assistant: Okay, you're repeating \"and\" a few times now. It really does feel ...\n",
      "----------------------------------------\n",
      "\n",
      "ï¿½ï¿½ AUDIO FEATURES:\n",
      "============================================================\n",
      "âŒ No audio features found\n",
      "\n",
      "ï¿½ï¿½ SUMMARY STATISTICS:\n",
      "============================================================\n",
      "   Mode Distribution:\n",
      "     ðŸ¤– Gemma conversations: 30\n",
      "     ðŸŽ¤ Listening conversations: 0\n",
      "   Speaker Distribution:\n",
      "     Gemma: 15 messages\n",
      "     Unknown: 15 messages\n",
      "   Session Distribution:\n",
      "     session_20250804_110036_520: 30 messages\n",
      "   Audio Features:\n",
      "     Total audio features: 0\n",
      "     Conversations with audio: 0\n",
      "\n",
      "âœ… Conversation review complete!\n"
     ]
    }
   ],
   "source": [
    "# View All Stored Conversations\n",
    "print(\"ï¿½ï¿½ ALL STORED CONVERSATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from utils.enhanced_conversation_db import EnhancedConversationDB\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize database\n",
    "db = EnhancedConversationDB()\n",
    "\n",
    "# Get all conversations\n",
    "all_conversations = db.conversation_collection.get()\n",
    "all_audio = db.audio_collection.get()\n",
    "\n",
    "print(f\"ðŸ“Š Database Summary:\")\n",
    "print(f\"   Total conversations: {len(all_conversations['documents'])}\")\n",
    "print(f\"   Total audio features: {len(all_audio['documents'])}\")\n",
    "print()\n",
    "\n",
    "# Display conversations in chronological order\n",
    "if all_conversations['documents']:\n",
    "    # Sort by timestamp\n",
    "    conversations_with_timestamps = []\n",
    "    for i, (doc, metadata) in enumerate(zip(all_conversations['documents'], all_conversations['metadatas'])):\n",
    "        timestamp = metadata.get('timestamp', '')\n",
    "        conversations_with_timestamps.append((timestamp, doc, metadata, all_conversations['ids'][i]))\n",
    "    \n",
    "    # Sort by timestamp (oldest first)\n",
    "    conversations_with_timestamps.sort(key=lambda x: x[0])\n",
    "    \n",
    "    print(\"ðŸ—‚ï¸  CONVERSATIONS (Chronological Order):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (timestamp, text, metadata, conv_id) in enumerate(conversations_with_timestamps, 1):\n",
    "        # Parse timestamp for display\n",
    "        try:\n",
    "            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))\n",
    "            formatted_time = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            formatted_time = timestamp\n",
    "        \n",
    "        print(f\"\\nðŸ“ Conversation #{i}\")\n",
    "        print(f\"   ID: {conv_id}\")\n",
    "        print(f\"   Time: {formatted_time}\")\n",
    "        print(f\"   Text: {text}\")\n",
    "        print(f\"   Speaker: {metadata.get('speaker', 'Unknown')}\")\n",
    "        print(f\"   Role: {metadata.get('role', 'Unknown')}\")\n",
    "        print(f\"   Mode: {'ï¿½ï¿½ Gemma' if metadata.get('is_gemma_mode') else 'ðŸŽ¤ Listening'}\")\n",
    "        print(f\"   Session: {metadata.get('session_id', 'Unknown')}\")\n",
    "        \n",
    "        # Audio features info\n",
    "        has_audio = metadata.get('has_audio_features', False)\n",
    "        print(f\"   Audio: {'âœ… Yes' if has_audio else 'âŒ No'}\")\n",
    "        \n",
    "        # Feedback info (if available)\n",
    "        if metadata.get('feedback_helpful') is not None:\n",
    "            feedback = metadata.get('feedback_helpful', 'Unknown')\n",
    "            feedback_response = metadata.get('feedback_response', '')\n",
    "            print(f\"   Feedback: {feedback}\")\n",
    "            if feedback_response:\n",
    "                print(f\"   Feedback Response: {feedback_response}\")\n",
    "        \n",
    "        # Clustering info (if available)\n",
    "        if metadata.get('clustered_speaker'):\n",
    "            print(f\"   Clustered Speaker: {metadata.get('clustered_speaker')}\")\n",
    "            print(f\"   Clustering Confidence: {metadata.get('clustering_confidence', 'Unknown')}\")\n",
    "        \n",
    "        # Conversation context (if available)\n",
    "        if metadata.get('conversation_context'):\n",
    "            context = metadata.get('conversation_context')\n",
    "            if len(context) > 100:\n",
    "                context = context[:100] + \"...\"\n",
    "            print(f\"   Context: {context}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No conversations found in database\")\n",
    "\n",
    "# Display audio features separately\n",
    "print(f\"\\nï¿½ï¿½ AUDIO FEATURES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if all_audio['documents']:\n",
    "    for i, (doc, metadata) in enumerate(zip(all_audio['documents'], all_audio['metadatas']), 1):\n",
    "        print(f\"\\nðŸŽµ Audio Feature #{i}\")\n",
    "        print(f\"   Conversation ID: {metadata.get('conversation_id', 'Unknown')}\")\n",
    "        print(f\"   Session: {metadata.get('session_id', 'Unknown')}\")\n",
    "        print(f\"   Speaker: {metadata.get('speaker', 'Unknown')}\")\n",
    "        print(f\"   Time: {metadata.get('timestamp', 'Unknown')}\")\n",
    "        print(f\"   Feature Count: {metadata.get('feature_count', 'Unknown')}\")\n",
    "        \n",
    "        # Parse the feature data\n",
    "        try:\n",
    "            feature_data = json.loads(doc)\n",
    "            feature_names = feature_data.get('feature_names', [])\n",
    "            features = feature_data.get('features', [])\n",
    "            print(f\"   Features: {len(features)} dimensions\")\n",
    "            if feature_names:\n",
    "                print(f\"   Feature Names: {', '.join(feature_names[:5])}{'...' if len(feature_names) > 5 else ''}\")\n",
    "        except:\n",
    "            print(f\"   Features: Error parsing feature data\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"âŒ No audio features found\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nï¿½ï¿½ SUMMARY STATISTICS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if all_conversations['documents']:\n",
    "    # Count by mode\n",
    "    gemma_count = sum(1 for m in all_conversations['metadatas'] if m.get('is_gemma_mode'))\n",
    "    listening_count = len(all_conversations['documents']) - gemma_count\n",
    "    \n",
    "    # Count by speaker\n",
    "    speakers = {}\n",
    "    for metadata in all_conversations['metadatas']:\n",
    "        speaker = metadata.get('speaker', 'Unknown')\n",
    "        speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "    \n",
    "    # Count by session\n",
    "    sessions = {}\n",
    "    for metadata in all_conversations['metadatas']:\n",
    "        session = metadata.get('session_id', 'Unknown')\n",
    "        sessions[session] = sessions.get(session, 0) + 1\n",
    "    \n",
    "    print(f\"   Mode Distribution:\")\n",
    "    print(f\"     ðŸ¤– Gemma conversations: {gemma_count}\")\n",
    "    print(f\"     ðŸŽ¤ Listening conversations: {listening_count}\")\n",
    "    \n",
    "    print(f\"   Speaker Distribution:\")\n",
    "    for speaker, count in speakers.items():\n",
    "        print(f\"     {speaker}: {count} messages\")\n",
    "    \n",
    "    print(f\"   Session Distribution:\")\n",
    "    for session, count in sessions.items():\n",
    "        print(f\"     {session}: {count} messages\")\n",
    "    \n",
    "    # Audio features summary\n",
    "    audio_count = len(all_audio['documents'])\n",
    "    conversations_with_audio = sum(1 for m in all_conversations['metadatas'] if m.get('has_audio_features'))\n",
    "    print(f\"   Audio Features:\")\n",
    "    print(f\"     Total audio features: {audio_count}\")\n",
    "    print(f\"     Conversations with audio: {conversations_with_audio}\")\n",
    "\n",
    "print(f\"\\nâœ… Conversation review complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_entries_by_session_id(self, session_id):\n",
    "    cursor = self.conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT speaker, role, text, timestamp\n",
    "        FROM conversations\n",
    "        WHERE session_id = ?\n",
    "        ORDER BY timestamp ASC\n",
    "    \"\"\", (session_id,))\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'speaker': row[0],\n",
    "            'role': row[1],\n",
    "            'text': row[2],\n",
    "            'timestamp': row[3]\n",
    "        }\n",
    "        for row in cursor.fetchall()\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03febb43",
   "metadata": {},
   "source": [
    "# ML Clustering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd766bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª ML CLUSTERING SYSTEM TEST\n",
      "==================================================\n",
      "âœ… Initial Clustering State:\n",
      "   Is clustered: False\n",
      "âœ… Generated Test Data:\n",
      "   Total samples: 16\n",
      "   Male samples: 8\n",
      "   Female samples: 8\n",
      "   Feature dimensions: 14\n",
      "\n",
      "ï¿½ï¿½ Testing K-means Clustering...\n",
      "âœ… Clustering Successful!\n",
      "   Clusters: 2\n",
      "   Samples: 16\n",
      "   Silhouette score: 0.187\n",
      "   Method: kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpeakerClustering' object has no attribute 'identify_speaker_from_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Test speaker identification\u001b[39;00m\n\u001b[32m     95\u001b[39m test_features = {\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33menergy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1300.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpitch_estimate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m110.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzero_crossings\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m38\u001b[39m,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mspectral_centroid\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m650.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_variance\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m160.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpeak_amplitude\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2600.0\u001b[39m,\n\u001b[32m     98\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrms_energy\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1050.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.32\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.22\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmfcc_3\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.12\u001b[39m,\n\u001b[32m     99\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformant_1\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m420.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mformant_2\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1250.0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjitter\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.019\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshimmer\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.026\u001b[39m\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m speaker_name, confidence = \u001b[43mclustering\u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_speaker_from_features\u001b[49m(test_features)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Speaker Identification Test:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Identified speaker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpeakerClustering' object has no attribute 'identify_speaker_from_features'"
     ]
    }
   ],
   "source": [
    "# Test 2: ML Clustering System Verification\n",
    "\n",
    "print(\"ðŸ§ª ML CLUSTERING SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test ML clustering system\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "clustering = SpeakerClustering()\n",
    "\n",
    "# Check initial state\n",
    "initial_stats = clustering.get_clustering_stats()\n",
    "print(f\"âœ… Initial Clustering State:\")\n",
    "print(f\"   Is clustered: {initial_stats['is_clustered']}\")\n",
    "\n",
    "# Create synthetic training data\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic audio features for testing\n",
    "def generate_synthetic_features(speaker_type=\"male\", num_samples=5):\n",
    "    \"\"\"Generate synthetic audio features for testing\"\"\"\n",
    "    features_list = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    base_features = {\n",
    "        'male': {\n",
    "            'energy': 1200.0, 'pitch_estimate': 100.0, 'formant_1': 400.0\n",
    "        },\n",
    "        'female': {\n",
    "            'energy': 2000.0, 'pitch_estimate': 180.0, 'formant_1': 600.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base = base_features[speaker_type]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Add some variation\n",
    "        features = {\n",
    "            'energy': base['energy'] + np.random.normal(0, 100),\n",
    "            'pitch_estimate': base['pitch_estimate'] + np.random.normal(0, 10),\n",
    "            'zero_crossings': 35 + np.random.normal(0, 5),\n",
    "            'spectral_centroid': 600 + np.random.normal(0, 50),\n",
    "            'energy_variance': 150 + np.random.normal(0, 20),\n",
    "            'peak_amplitude': 2500 + np.random.normal(0, 200),\n",
    "            'rms_energy': 1000 + np.random.normal(0, 100),\n",
    "            'mfcc_1': 0.3 + np.random.normal(0, 0.05),\n",
    "            'mfcc_2': 0.2 + np.random.normal(0, 0.05),\n",
    "            'mfcc_3': 0.1 + np.random.normal(0, 0.05),\n",
    "            'formant_1': base['formant_1'] + np.random.normal(0, 20),\n",
    "            'formant_2': 1200 + np.random.normal(0, 50),\n",
    "            'jitter': 0.018 + np.random.normal(0, 0.005),\n",
    "            'shimmer': 0.025 + np.random.normal(0, 0.005)\n",
    "        }\n",
    "        \n",
    "        features_list.append(list(features.values()))\n",
    "        metadata_list.append({\n",
    "            'conversation_id': f'test_conv_{speaker_type}_{i}',\n",
    "            'session_id': f'test_session_{speaker_type}',\n",
    "            'speaker': f'{speaker_type.capitalize()}Speaker',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'feature_count': 14\n",
    "        })\n",
    "    \n",
    "    return features_list, metadata_list\n",
    "\n",
    "# Generate test data\n",
    "male_features, male_metadata = generate_synthetic_features(\"male\", 8)\n",
    "female_features, female_metadata = generate_synthetic_features(\"female\", 8)\n",
    "\n",
    "# Combine all features\n",
    "all_features = male_features + female_features\n",
    "all_metadata = male_metadata + female_metadata\n",
    "\n",
    "print(f\"âœ… Generated Test Data:\")\n",
    "print(f\"   Total samples: {len(all_features)}\")\n",
    "print(f\"   Male samples: {len(male_features)}\")\n",
    "print(f\"   Female samples: {len(female_features)}\")\n",
    "print(f\"   Feature dimensions: {len(all_features[0])}\")\n",
    "\n",
    "# Test clustering\n",
    "print(f\"\\nï¿½ï¿½ Testing K-means Clustering...\")\n",
    "result = clustering.perform_clustering(\n",
    "    all_features, all_metadata,\n",
    "    method='kmeans',\n",
    "    n_clusters=2\n",
    ")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"âœ… Clustering Successful!\")\n",
    "    print(f\"   Clusters: {result['n_clusters']}\")\n",
    "    print(f\"   Samples: {result['n_samples']}\")\n",
    "    print(f\"   Silhouette score: {result['silhouette_score']:.3f}\")\n",
    "    print(f\"   Method: {result['method']}\")\n",
    "    \n",
    "    # Test speaker identification\n",
    "    test_features = {\n",
    "        'energy': 1300.0, 'pitch_estimate': 110.0, 'zero_crossings': 38,\n",
    "        'spectral_centroid': 650.0, 'energy_variance': 160.0, 'peak_amplitude': 2600.0,\n",
    "        'rms_energy': 1050.0, 'mfcc_1': 0.32, 'mfcc_2': 0.22, 'mfcc_3': 0.12,\n",
    "        'formant_1': 420.0, 'formant_2': 1250.0, 'jitter': 0.019, 'shimmer': 0.026\n",
    "    }\n",
    "    \n",
    "    speaker_name, confidence = clustering.identify_speaker_from_features(test_features)\n",
    "    print(f\"âœ… Speaker Identification Test:\")\n",
    "    print(f\"   Identified speaker: {speaker_name}\")\n",
    "    print(f\"   Confidence: {confidence:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Clustering failed: {result.get('reason', 'unknown')}\")\n",
    "\n",
    "print(\"ðŸŽ‰ ML clustering system is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration test\n",
    "\n",
    "# Test 3: Database + ML Integration Test\n",
    "print(\"ðŸ§ª INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the complete pipeline\n",
    "from speech.speech_processor import SpeakerDetector\n",
    "from ml.speaker_clustering import SpeakerClustering\n",
    "\n",
    "# Initialize components\n",
    "db = EnhancedConversationDB()\n",
    "clustering = SpeakerClustering()\n",
    "speaker_detector = SpeakerDetector(\n",
    "    enhanced_db=db,\n",
    "    speaker_clustering=clustering\n",
    ")\n",
    "\n",
    "print(f\"âœ… Components Initialized:\")\n",
    "print(f\"   Database: {type(db).__name__}\")\n",
    "print(f\"   Clustering: {type(clustering).__name__}\")\n",
    "print(f\"   Speaker Detector: {type(speaker_detector).__name__}\")\n",
    "\n",
    "# Test speaker detection with ML\n",
    "import numpy as np\n",
    "\n",
    "# Simulate audio processing\n",
    "dummy_audio = np.random.randint(-1000, 1000, size=2048, dtype=np.int16).tobytes()\n",
    "\n",
    "print(f\"\\nðŸ”§ Testing Speaker Detection with ML:\")\n",
    "print(f\"   Initial speaker: {speaker_detector.current_speaker}\")\n",
    "\n",
    "# Process multiple audio frames to build up features\n",
    "for i in range(10):\n",
    "    speaker_detector.update_speaker_count(dummy_audio, 0)\n",
    "\n",
    "print(f\"   After processing: {speaker_detector.current_speaker}\")\n",
    "print(f\"   Speaker changes: {speaker_detector.speaker_changes}\")\n",
    "print(f\"   Feature buffer size: {len(speaker_detector.feature_buffer)}\")\n",
    "\n",
    "# Test feature extraction\n",
    "current_features = speaker_detector.get_current_features()\n",
    "print(f\"   Current features available: {current_features is not None}\")\n",
    "if current_features:\n",
    "    print(f\"   Feature count: {len(current_features)}\")\n",
    "\n",
    "# Test database integration\n",
    "if current_features:\n",
    "    # Add to database\n",
    "    db.add_conversation_with_audio(\n",
    "        session_id=\"integration_test\",\n",
    "        text=\"Integration test conversation\",\n",
    "        speaker=speaker_detector.current_speaker,\n",
    "        role=\"user\",\n",
    "        is_gemma_mode=False,\n",
    "        audio_features=current_features\n",
    "    )\n",
    "    \n",
    "    # Verify storage\n",
    "    stats = db.get_conversation_stats()\n",
    "    print(f\"âœ… Database Integration:\")\n",
    "    print(f\"   Total conversations: {stats['total_conversations']}\")\n",
    "    print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "\n",
    "print(\"ðŸŽ‰ Integration test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee07c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline test\n",
    "\n",
    "# Test 4: Training Pipeline Test\n",
    "print(\"ðŸ§ª TRAINING PIPELINE TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test the training script functionality\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the tests directory to path\n",
    "sys.path.append('tests')\n",
    "\n",
    "# Import the training function\n",
    "from train_unsupervised_speakers_new import train_unsupervised_speakers, analyze_clustering_quality\n",
    "\n",
    "print(\"âœ… Training functions imported successfully\")\n",
    "\n",
    "# Check if we have enough data for training\n",
    "stats = db.get_conversation_stats()\n",
    "print(f\"ðŸ“Š Current Data Status:\")\n",
    "print(f\"   Audio features: {stats['total_audio_features']}\")\n",
    "print(f\"   Need for training: 10+\")\n",
    "\n",
    "if stats['total_audio_features'] >= 10:\n",
    "    print(\"âœ… Sufficient data for training!\")\n",
    "    print(\"   Run: train_unsupervised_speakers() to train clustering\")\n",
    "else:\n",
    "    print(\"â³ Need more data for training\")\n",
    "    print(\"   Continue using the system to collect more audio features\")\n",
    "\n",
    "# Test analysis function\n",
    "print(f\"\\nðŸ” Testing Analysis Function:\")\n",
    "try:\n",
    "    analyze_clustering_quality()\n",
    "    print(\"âœ… Analysis function works!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Analysis function error: {e}\")\n",
    "\n",
    "print(\"ðŸŽ‰ Training pipeline test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5a272",
   "metadata": {},
   "source": [
    "# Delete database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ba66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Old database deleted - ready for 14-feature data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"âœ… Old database deleted - ready for 14-feature data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f399dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database cleared for fresh start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedConversationDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Database cleared for fresh start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create completely fresh database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m db = \u001b[43mEnhancedConversationDB\u001b[49m()\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Fresh database ready\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EnhancedConversationDB' is not defined"
     ]
    }
   ],
   "source": [
    "# Final database clear\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"data/vector_db\"):\n",
    "    shutil.rmtree(\"data/vector_db\")\n",
    "    print(\"âœ… Database cleared for fresh start\")\n",
    "\n",
    "# Create completely fresh database\n",
    "db = EnhancedConversationDB()\n",
    "print(\"âœ… Fresh database ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
